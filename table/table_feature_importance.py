#!/usr/bin/env python
# coding: utf-8

# # –ê–Ω–∞–ª–∏–∑ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –∏—Ö –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏

# ## –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫

# In[3]:


import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

from scipy import stats

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor

from sklearn.inspection import permutation_importance

import shap


# ## –ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö

# In[4]:


### –î–ª—è —Ä–∞–±–æ—Ç—ã —Å BIGDATA
for chunk in pd.read_csv("big.csv", chunksize=200_000):
    chunk.to_parquet("data.parquet", engine="pyarrow", append=True)


df = pd.read_csv('data/Air_Quality.csv')

# –î–æ–±–∞–≤–∏–º —Å–ª—É—á–∞–π–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è, –∫–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ.
df["random_feature1"] = np.random.rand(len(df)) * 10
df["random_feature2"] = np.random.rand(len(df)) * 100
df["random_feature3"] = np.random.rand(len(df))

# –î–ª—è –∞–Ω–∞–ª–∏–∑–∞ –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
numeric_features = df.select_dtypes('number').columns

df = df[numeric_features]
df.head(3)


# ## –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö

# ### –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

# In[5]:


plt.figure(figsize=(15, 10))

for i, col in enumerate(numeric_features, 1):
    plt.subplot(3, 4, i)
    sns.histplot(df[col], kde=True)
    plt.title(col)

plt.tight_layout()
plt.show()


# –í–∏–¥–Ω—ã —Å—Ç—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –∏–º–µ—é—Ç —Å–ø–ª–æ—à–Ω–æ–π –≥—Ä–∞—Ñ–∏–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è.

# ## –û—Ü–µ–Ω–∫–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
# 
# –ü–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∑–∞–π–º–µ–º—Å—è –æ—Ü–µ–Ω–∫–æ–π –≤–∞–∂–Ω–æ—Å—Ç–∏ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
# 
# –ù–∏–∂–µ –±—É–¥—É—Ç —Ä–∞–∑–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã –∫ –æ—Ü–µ–Ω–∫–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤. –í —Ä–∞–±–æ—Ç–µ –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–¥—Ö–æ–¥–æ–≤, —Ç–∞–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –±—É–¥–µ—Ç –æ–±—ä–µ–∫—Ç–∏–≤–Ω–µ–µ.

# ### –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑

# - –°–∏–ª—å–Ω–æ –∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –º–æ–≥—É—Ç –ø—Ä–∏–≤–æ–¥–∏—Ç—å –∫ –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç–∏
# 
# - –¢–∞–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –º–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å –∏–ª–∏ –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å

# In[6]:


corr_matrix = df[numeric_features].corr()

corr_matrix


# In[7]:


plt.figure(figsize=(9, 6))
sns.heatmap(corr_matrix, cmap="coolwarm", annot=False)
plt.title("–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞")
plt.show()


# In[8]:


corr_with_target = corr_matrix["AQI"].sort_values(ascending=False)
corr_with_target


# –î–ª—è 3 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –Ω—É–ª–µ–≤–∞—è.

# ### –î–∏—Å–ø–µ—Ä—Å–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (ANOVA)
# 
# –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –æ—Ç —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π.
# 
# ANOVA –Ω–µ –ø—Ä–∏–º–µ–Ω–∏–º–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–π —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –±–µ–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–∫—Ç–æ—Ä–∞. –í —Å–≤—è–∑–∏ —Å —ç—Ç–∏–º —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è AQI –±—É–¥–µ–º –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ –∫–ª–∞—Å—Å—ã, –ø–æ—Å–ª–µ —á–µ–≥–æ –ø—Ä–æ–≤–µ–¥–µ–º –æ–¥–Ω–æ—Ñ–∞–∫—Ç–æ—Ä–Ω—ã–π –¥–∏—Å–ø–µ—Ä—Å–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.

# In[9]:


# –°–Ω–∞—á–∞–ª–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∏—Ä—É–µ–º AQI –≤ –∫–ª–∞—Å—Å—ã

df["AQI_class"] = pd.cut(
    df["AQI"],
    bins=[0, 20, 25, 45, 70, np.inf],
    labels=[0, 1, 2, 3, 4]
)

df['AQI_class'].value_counts()


# In[10]:


anova_results = {}

for col in numeric_features:
  groups = []
  for name, group in df.groupby("AQI_class", observed=False):
      groups.append(group[col].values)  # –¥–æ–±–∞–≤–ª—è–µ–º –º–∞—Å—Å–∏–≤ –∑–Ω–∞—á–µ–Ω–∏–π –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞

  f_stat, p_value = stats.f_oneway(*groups)
  anova_results[col] = p_value


pd.options.display.float_format = '{:.4f}'.format
anova_results = pd.Series(anova_results).sort_values()
anova_results


# üìå –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:
# - p-value < 0.05 ‚Äî –ø—Ä–∏–∑–Ω–∞–∫ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º
# - p-value > 0.05 ‚Äî –≤–ª–∏—è–Ω–∏–µ –Ω–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–æ
# 
# 
# –ò—Å—Ö–æ–¥—è –∏–∑ –¥–∏—Å–ø–µ—Ä—Å–∏–æ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã –¥–ª—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π (AQI), –∫—Ä–æ–º–µ —Å–ª—É—á–∞–π–Ω—ã—Ö. –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ —Å–ª—É—á–∞–π–Ω—ã–º –º–æ–≥—É—Ç –±—ã—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ –º—É—Å–æ—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏.

# In[11]:


df


# In[12]:


df = df.drop('AQI_class', errors='ignore', axis=1)


# ## –í–∞–∂–Ω–æ!
# 
# –î–ª—è –¥–∞–ª—å–Ω–µ–π—à–Ω–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –º—ã –±—É–¥–µ–º –æ—Ü–µ–Ω–∏–≤–∞—Ç—å –≤–∑–∞–∏–º–æ—Å–≤—è–∑—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –∏–Ω—Ñ—Ä–µ—Ä–µ–Ω—Å—É –º–æ–¥–µ–ª–∏, –ø–æ—ç—Ç–æ–º—É –æ–±—É—á–∏–º –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å RandomForest –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏.

# In[13]:


target = "AQI"

# –î–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞ –±–µ—Ä–µ–º –ª–∏—à—å —á–∞—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
sample_indx = df.sample(5000).index

X = df.drop(columns=[target]).iloc[sample_indx]
y = df[target].iloc[sample_indx]


# In[14]:


X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)


# In[15]:


model = RandomForestRegressor(
    n_jobs=-1
)

model.fit(X_train, y_train)


# ### SHAP-–∞–Ω–∞–ª–∏–∑

# In[16]:


explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test)


# In[17]:


shap.summary_plot(shap_values, X_test)


# In[18]:


mean_abs_shap = np.abs(shap_values).mean(axis=0)

# –°–æ–∑–¥–∞—ë–º —Ç–∞–±–ª–∏—Ü—É —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
shap_df = pd.DataFrame({
    "Feature": X_test.columns,        # –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    "MeanAbsSHAP": mean_abs_shap       # —Å—Ä–µ–¥–Ω–µ–µ –∞–±—Å–æ–ª—é—Ç–Ω–æ–µ SHAP
})

# –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
shap_df = shap_df.sort_values(by="MeanAbsSHAP", ascending=False)
shap_df


# –ü–æ SHAP –∞–Ω–∞–ª–∏–∑—É –∏–∑ –≥—Ä–∞—Ñ–∏–∫–∞ –∏ —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤–∞–∂–Ω–æ—Å—Ç–∏, —Å–∞–º—ã–µ –Ω–µ—Ä–µ–ª–µ–≤–∞—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:
# - random_feature1
# - random_feature2
# - random_feature3

# ### Permutation Importance

# In[21]:


perm_importance = permutation_importance(
    model, X_test, y_test, n_repeats=10
)

importances = pd.Series(
    perm_importance.importances_mean,
    index=X.columns
).sort_values(ascending=False)

importances


# In[22]:


plt.figure(figsize=(10, 6))
importances.plot(kind="bar")
plt.title("Permutation Importance")
plt.show()


# –ü–æ –∞–Ω–∞–ª–∏–∑—É Permutation Importance - —Å–ª—É—á–∞–π–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ç–∞–∫–∂–µ –Ω–µ–≤–∞–∂–Ω—ã –¥–ª—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π.

# ## –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞–∏–º–µ–Ω–µ–µ –∑–Ω–∞—á–∏–º—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
# 
# 
# –¢—É—Ç —É–∂–µ –∏—Å—Ö–æ–¥—è –∏–∑ –ø—Ä–æ–≤–µ–¥–µ–Ω–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤ –ø–æ–ø—Ä–æ—Å—è—Ç –≤—ã–∫–∏–Ω—É—Ç—å –Ω–µ–≤–∞–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –±–µ—Ä–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –Ω–µ–≤–∞–∂–Ω—ã—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–ª—É—á–∞–π–Ω—ã—Ö), –∏ –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ–º –∏–∑ –æ—Å–Ω–æ–≤–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞.
# 
# –í–∞–∂–Ω–æ, –∞—Ä–≥—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ—á–µ–º—É –º—ã —ç—Ç–æ –¥–µ–ª–∞–µ–º. –¢–∞–∫–∂–µ –Ω—É–∂–Ω–æ –∞—Ä–≥—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å, –ø–æ—á–µ–º—É –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –Ω–µ–≤–∞–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤—Å–µ-—Ç–∞–∫–∏ –Ω—É–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å: –∞–π–¥–∏, –º–µ—Ç–∫–∏ –∏ —Ç–¥.

# In[23]:


df_total = df.drop(['random_feature1', 'random_feature2', 'random_feature3'], axis=1)
df_total.head()


# ## –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö
# 
#  ‚Äî —ç—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å –ø—Ä–∏–≤–µ–¥–µ–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ –∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–æ–≥—Ä–∞–º–º—ã –∫ —Ç–∞–∫–∏–º —Ç–∏–ø–∞–º –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–µ –∑–∞–Ω–∏–º–∞—é—Ç –º–µ–Ω—å—à–µ –ø–∞–º—è—Ç–∏, —Ä–∞–±–æ—Ç–∞—é—Ç –±—ã—Å—Ç—Ä–µ–µ –∏ –ø—Ä–∏ —ç—Ç–æ–º –Ω–µ —Ç–µ—Ä—è—é—Ç –Ω—É–∂–Ω—É—é —Ç–æ—á–Ω–æ—Å—Ç—å.

# In[24]:


df_total.info()


# memory usage: 4.0 MB
# 
# –≠—Ç–æ –∑–Ω–∞—á–∏—Ç —á—Ç–æ —Å–µ–π—á–∞—Å –≤ –ø–∞–º—è—Ç–∏ –¥–∞—Ç–∞—Å–µ—Ç –∑–∞–Ω–∏–º–∞–µ—Ç —Ç–∞–∫–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –ø–∞–º—è—Ç–∏.
# 
# 
# –ü–æ–ø—Ä–æ–±—É–µ–º –¥–ª—è –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–º–µ–Ω–∏—Ç—å —Ç–∏–ø –Ω–∞ float32. –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –º—ã –Ω–µ –ø–æ—Ç–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã—Ö, –Ω–æ –æ–±–µ—Å–ø–µ—á–∏–º –±–æ–ª–µ–µ —É–º–µ—Ä–µ–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö. 

# In[25]:


df_total = df_total.astype('float32')

df_total.info()


# memory usage: 1.4 MB
# 
# 
# –ê —ç—Ç–æ –∑–Ω–∞—á–∏—Ç, —á—Ç–æ –º—ã –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–ª–∏ –¥–∞—Ç–∞—Å–µ—Ç –≤ 2 —Ä–∞–∑–∞.

# ## –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º —Å–∂–∞—Ç–∏–µ–º
# 
# –°–æ—Ö—Ä–∞–Ω–∏–º –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–æ—Ä–º–∞—Ç–µ parquet —Å –ø–æ–º–æ—â—å—é —Å–∂–∞—Ç–∏—è zstd. –≠—Ç–æ –æ–¥–∏–Ω –∏–∑ —Å–∞–º—ã—Ö —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤,
# —Å–æ—á–µ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–µ–µ —Å–∂–∞—Ç–∏–µ –∏ –≤—ã—Å–æ–∫—É—é —Å–∫–æ—Ä–æ—Å—Ç—å.

# In[26]:


df_total.to_parquet(
    'data/data.parquet',
    compression='zstd'
)

