#!/usr/bin/env python
# coding: utf-8

# # üîπ –ü—É–Ω–∫—Ç 1: —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –Ω–∞ –∑–≤—É–∫–∏ ‚Üí –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è ‚Üí –¥–∞—Ç–∞—Å–µ—Ç ‚Üí train/val/test
# 
# 
# –ø—É—Å—Ç—å —É –Ω–∞—Å –µ—Å—Ç—å –¥–ª–∏–Ω–Ω—ã–π(–Ω–∞ 32 –º–∏–Ω—É—Ç—ã –∞—É–¥–∏–æ —Ñ–∞–π–ª audio.wav –∏ mata.csv, –∫–æ—Ç–æ—Ä–∞—è –∫–æ–≥–æ–≤–æ—Ä–∏—Ç, –≤ –∫–∞–∫–∏—Ö –æ—Ç—Ä–µ–∑–∫–∞—Ö –≤—Ä–µ–º–µ–Ω–∏ –∫–∞–∫–æ–π –∫–ª–∞—Å—Å)
# 

# 1. –∑–∞–≥—Ä—É–∑–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫ + –∑–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞

# In[2]:


import numpy as np
import pandas as pd
import librosa
import librosa.display
import matplotlib.pyplot as plt
from pathlib import Path
from sklearn.model_selection import GroupShuffleSplit

AUDIO_PATH = "audio.wav"

y, sr = librosa.load(AUDIO_PATH, sr=None, mono=True)
duration = len(y) / sr

print("sr:", sr, "–ì—Ü") #—á–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
print("–¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:", round(duration, 2), "—Å–µ–∫") 
print("—Å—ç–º–ø–ª—ã:", len(y)) #–∫–æ–ª-–≤–æ —Å—ç–º–ø–ª–æ–≤


# 2. –ø–æ—Å—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫ –∞–º–ø–ª–∏—Ç—É–¥—ã –∑–≤—É–∫–∞

# In[3]:


plt.figure(figsize=(14, 4))
librosa.display.waveshow(y, sr=sr, alpha=0.7)
plt.tight_layout()
plt.show()


# 3. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–∏–≥–Ω–∞–ª–∞ –∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –Ω–∞ –∑–≤—É–∫–∏
# 
# 
# –ü—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –∞—É–¥–∏–æ librosa —Ä–∞–∑–±–∏–≤–∞–µ—Ç —Å–∏–≥–Ω–∞–ª –Ω–∞ –∫–æ—Ä–æ—Ç–∫–∏–µ –æ–∫–Ω–∞ (—Ñ—Ä–µ–π–º—ã) –∏ —Å–¥–≤–∏–≥–∞–µ—Ç –æ–∫–Ω–æ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å —à–∞–≥–æ–º hop_length (–≤ —Å—ç–º–ø–ª–∞—Ö).
# 
# –ï—Å–ª–∏ sr = 44100 –∏ hop_length = 512, —Ç–æ –æ–¥–∏–Ω —à–∞–≥ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Ä–∞–≤–µ–Ω 
# 512/44100‚âà0.0116 —Å–µ–∫—É–Ω–¥—ã ‚Äî –ø—Ä–∏–º–µ—Ä–Ω–æ 11.6 –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥.
# ‚Äã
# –¢–æ –µ—Å—Ç—å onset‚Äë—ç–Ω–µ—Ä–≥–∏—è o_env ‚Äî —ç—Ç–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∑–Ω–∞—á–µ–Ω–∏–π —á–µ—Ä–µ–∑ –∫–∞–∂–¥—ã–µ ~11.6 –º—Å. –ß–µ–º –º–µ–Ω—å—à–µ hop_length, —Ç–µ–º —Ç–æ—á–Ω–µ–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏, –Ω–æ —Ç–µ–º –±–æ–ª—å—à–µ —Ç–æ—á–µ–∫ –∏ –Ω–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è.
# ‚Äã
# 
#  - –ö–∞–∫ –ø—Ä–∏–º–µ—Ä–Ω–æ –≤—ã–±–∏—Ä–∞—Ç—å hop_length
# –î–ª—è –æ–±—â–µ–≥–æ –∞—É–¥–∏–æ/–º—É–∑—ã–∫–∏/–∑–≤—É–∫–æ–≤ —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç 256, 512 –∏–ª–∏ 1024.
# –ï—Å–ª–∏  —Å–æ–±—ã—Ç–∏—è –¥–ª—è—Ç—Å—è –¥–µ—Å—è—Ç–∫–∏‚Äì—Å–æ—Ç–Ω–∏ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥, —à–∞–≥ –≤ —Ä–∞–π–æ–Ω–µ 10‚Äì20 –º—Å (—Ç–æ –µ—Å—Ç—å hop_length ‚âà sr/100 ‚Äì sr/50) –¥–∞—ë—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ.
# 
# 

# In[4]:


hop_length = 512

o_env = librosa.onset.onset_strength(y=y, sr=sr, hop_length=hop_length) #–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–¥–Ω–æ–º–µ—Ä–Ω—ã–π –º–∞—Å—Å–∏–≤ o_env, –≥–¥–µ –∫–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∫–∞–¥—Ä—É –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–∏–ª—É –ø–æ—è–≤–ª–µ–Ω–∏—è —Å–æ–±—ã—Ç–∏—è 

onset_frames = librosa.onset.onset_detect(
    onset_envelope=o_env,
    sr=sr,
    hop_length=hop_length,
    backtrack=True,
    units="frames"
)
# –Ω–∞—Ö–æ–¥–∏—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∫–∞–¥—Ä—ã onset_frames, –≥–¥–µ –ø—Ä–æ–∏—Å—Ö–æ–¥—è—Ç onsets (–Ω–∞—á–∞–ª–∞ –∑–≤—É–∫–æ–≤). –ü–∞—Ä–∞–º–µ—Ç—Ä backtrack=True —Å–¥–≤–∏–≥–∞–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã–π onset –Ω–∞–∑–∞–¥ –∫ –±–ª–∏–∂–∞–π—à–µ–º—É –º–∏–Ω–∏–º—É–º—É —ç–Ω–µ—Ä–≥–∏–∏, —á—Ç–æ –¥–∞—ë—Ç –±–æ–ª–µ–µ –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–µ —Ç–æ—á–∫–∏ —Ä–∞–∑—Ä–µ–∑–∞ –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏

onset_times = librosa.frames_to_time(onset_frames, sr=sr, hop_length=hop_length) #–ø–µ—Ä–µ–≤–æ–¥–∏–º –∫–∞–¥—Ä—ã –≤ —Å–µ–∫—É–Ω–¥—ã

print("n_onsets:", len(onset_frames))


# 4. –ù–∞—Ä–∏—Å—É–µ–º –≥—Ä–∞—Ñ–∏–∫ —Å–∏–≥–Ω–∞–ª–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ + –Ω–∞ –Ω–µ–º –∫—Ä–∞—Å–Ω—ã–º–∏ –ø—É–Ω–∫—Ç–∏—Ä–∞–º–∏ –æ–±–æ—á–∑–Ω–∞—á–∏–º —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ –æ—Ç—Ä–µ–∑–∫–∏(–≥—Ä–∞–Ω–∏—Ü—ã —Å–µ–≥–º–µ–Ω—Ç–æ–≤)

# In[5]:


plt.figure(figsize=(14, 4))
librosa.display.waveshow(y, sr=sr, alpha=0.6)
plt.vlines(onset_times, ymin=y.min(), ymax=y.max(), color="r", alpha=0.4, linestyle="--")
plt.tight_layout()
plt.show()


# 5. —Ä–µ–∂–µ–º –Ω–∞—à–µ –∞—É–¥–∏–æ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∫—É—Å–∫–∏ –∏ —Å–∫–ª–∞–¥—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–∏—Ö –≤ —Ç–∞–±–ª–∏—Ü—É

# In[7]:


onset_samples = librosa.frames_to_samples(onset_frames, hop_length=hop_length)
cut_points = np.unique(np.concatenate([[0], onset_samples, [len(y)]]))

min_dur = 0.2  # –º–∏–Ω–∏–º—É–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–µ–≥–º–µ–Ω—Ç–∞, —Å–µ–∫

segments = []
for i in range(len(cut_points) - 1):
    start = int(cut_points[i])
    end = int(cut_points[i + 1])
    seg_y = y[start:end]
    dur = (end - start) / sr
    if dur >= min_dur:
        segments.append({
            "segment_id": len(segments),
            "start_sample": start,
            "end_sample": end,
            "start_time": start / sr,
            "end_time": end / sr,
            "duration": dur,
            "y": seg_y,
            "label": "unknown"   # –ø–æ–∫–∞ –Ω–µ –∑–Ω–∞–µ–º –∫–ª–∞—Å—Å
        })

df_segments = pd.DataFrame(segments)
df_segments.head()


# –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ 

# In[8]:


df_segments["duration"].describe()


# In[9]:


plt.figure(figsize=(8, 3))
plt.hist(df_segments["duration"], bins=40)
plt.xlabel("–¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (—Å–µ–∫)")
plt.ylabel("–∫–æ–ª-–≤–æ")
plt.tight_layout()
plt.show()


# 5. –ø–æ—á–∏—Å—Ç–∏–º —Å–µ–≥–º–µ–Ω—Ç—ã —Ç–∏—à–∏–Ω—ã (–∫–æ—Ç–æ—Ä—ã–µ –≤ –¥–∞–ª—å–Ω–µ—à–µ–º –±—É–¥—É—Ç —Ç–æ–ª—å–∫–æ –º–µ—à–∞—Ç—å –æ–±—É—á–µ–Ω–∏—é)

# In[10]:


# —Å—á–∏—Ç–∞–µ–º —Å—Ä–µ–¥–Ω—é—é —ç–Ω–µ—Ä–≥–∏—é (RMS) –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
rms_means = []
for seg in df_segments["y"]:
    rms = librosa.feature.rms(y=seg).mean()
    rms_means.append(rms)

df_segments["rms_mean"] = rms_means

# —Å–º–æ—Ç—Ä–∏–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ RMS, —á—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å, –∫–∞–∫–æ–π –ø–æ—Ä–æ–≥ —Ç–∏—à–∏–Ω—ã –≤—ã–±—Ä–∞—Ç—å
print(df_segments["rms_mean"].describe())

# –ø—É—Å—Ç—å –Ω–∏–∂–Ω–∏–µ 10% –ø–æ –≥—Ä–æ–º–∫–æ—Å—Ç–∏ ‚Äî —ç—Ç–æ —Ç–∏—à–∏–Ω–∞
silence_thr = df_segments["rms_mean"].quantile(0.10)

# –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å–µ–≥–º–µ–Ω—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –≥—Ä–æ–º—á–µ —Ç–∏—à–∏–Ω—ã
df_segments = df_segments[df_segments["rms_mean"] > silence_thr].reset_index(drop=True)

print("–°–µ–≥–º–µ–Ω—Ç–æ–≤ –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è —Ç–∏—à–∏–Ω—ã:", len(df_segments))


# 6. –ø–æ—Å–º–æ—Ç—Ä–∏–º —Ñ–∞–π–ª meta, –∫–æ—Ç–æ—Ä—ã–π —Ö—Ä–∞–Ω–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø—Ä–æ –∫–ª–∞—Å—Å—ã

# In[11]:


meta_df = pd.read_csv("meta_df.csv")
meta_df.head()


# 7. –Ω–∞–ø–∏—à–µ–º —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ—Ç –∫–∞–∂–¥–æ–º—É –∞—É–¥–∏–æ-—Å–≥–µ–º–µ–Ω—Ç—É –º–µ—Ç–∫—É –∫–ª–∞—Å—Å–∞, –≥–ª—è–¥—è –Ω–∞ –≤—Ä–º–µ–Ω–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã 

# In[12]:


def assign_label(seg_row, meta_df):
    mid = (seg_row["start_time"] + seg_row["end_time"]) / 2.0
    hits = meta_df[(meta_df["start_time"] <= mid) & (meta_df["end_time"] >= mid)]
    return hits.iloc[0]["label"]


# 8. –¥–æ–ø–æ–ª–Ω–∏–º –º–µ—Ç–∫–∞–º–∏ –∫–ª–∞—Å—Å–∞ –≤—Å–µ –Ω–∞—à–∏ —Å–µ–≥–º–µ–Ω—Ç—ã

# In[13]:


df_segments["label"] = df_segments.apply(lambda r: assign_label(r, meta_df), axis=1)
df_segments["label"].value_counts()
df_segments.head()


# In[14]:


dataset_df = df_segments.drop(columns=["y"]).copy()
dataset_df.head()


# 9. –æ—Ç—Ñ–∏–ª—å—Å—Ç—Ä—É–µ–º –¥–∞—Ç–∞—Å—ç—Ç —É–¥–∞–ª–∏–≤ –º–µ—Ç–∫–∏, –≥–¥–µ –Ω–µ—Ç –º–µ—Ç–∫–∏

# In[15]:


dataset_labeled = dataset_df[dataset_df["label"].isin(["cat", "dog"])].reset_index(drop=True)
print("–í—Å–µ–≥–æ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤:", len(dataset_labeled))
print(dataset_labeled["label"].value_counts())


# 10. –¥–µ–ª–∏–º –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—ã–µ –≤—ã–±–æ—Ä–∫–∏ 80/20

# In[16]:


from sklearn.model_selection import train_test_split

train_val_df, test_df = train_test_split(
    dataset_labeled,
    test_size=0.2,          
    random_state=42,
    stratify=dataset_labeled["label"]
)

print("Train+Val:", len(train_val_df), "Test:", len(test_df))
print("Test labels:\n", test_df["label"].value_counts())


# 11. –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –º–æ–∂–µ–º –ø–æ–µ–¥–ª–∏—Ç—å –Ω–∞ train –∏ val

# In[17]:


train_df, val_df = train_test_split(
    train_val_df,
    test_size=0.2,        
    random_state=42,
    stratify=train_val_df["label"]
)

print("Train:", len(train_df), "Val:", len(val_df), "Test:", len(test_df))


#  üîπ –º–æ–º–µ–Ω—Ç: –º–æ–∂–µ—Ç –±—ã—Ç—å —á—Ç–æ –≤ –∑–∞–ø–∏—Å–∏ –±—É–¥—É—Ç —Å—Ç—Ä–æ–≥–æ –∏–∑–≤–µ—Å—Ç–Ω—ã –º–æ–º–µ–Ω—Ç—ã —á–µ—Ä–µ–∑ –∫–æ—Ä–æ—Ç—ã–µ —Ä–µ–∑–∞—Ç—å, –¥–æ–ø—É—Å—Ç–∏–º –ø–∞—É–∑—ã –ø–æ 1 —Å–µ–∫, –≤ —Ç–∞–∫–æ–º —Å–ª—É—á–∞–µ –º–æ–∂–Ω–æ —Ä–∞–∑–±–∏—Ç—Ç—å –∞—É–¥–∏–æ—Ñ–∞–π–ª —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º

# In[18]:


import librosa
import soundfile as sf
import numpy as np
from pathlib import Path

audio_path = "long_audio.wav"
out_dir = Path("segments")
out_dir.mkdir(exist_ok=True)

y, sr = librosa.load(audio_path, sr=None, mono=True)

silence_threshold = 1e-3 # –ø–æ—Ä–æ–≥ —Ç–∏—à–∏–Ω—ã
one_sec = sr # —Ä–æ–≤–Ω–æ 1 —Å–µ–∫—É–Ω–¥–∞ –≤ —Å—ç–º–ø–ª–∞—Ö

is_silent = np.abs(y) < silence_threshold

segments = []
current_start = 0
silent_run = 0

for i, silent in enumerate(is_silent):
    if silent:
        silent_run += 1
    else:
        # —Ç–æ–ª—å–∫–æ —á—Ç–æ –∑–∞–∫–æ–Ω—á–∏–ª–∞—Å—å —Ç–∏—à–∏–Ω–∞
        if silent_run > 0:
            if silent_run == one_sec:
                # –†–û–í–ù–û 1 —Å–µ–∫ —Ç–∏—à–∏–Ω—ã -> —Ä–µ–∂–µ–º
                cut_pos = i - silent_run
                if cut_pos > current_start:
                    segments.append((current_start, cut_pos))
                    current_start = i  # –Ω–æ–≤—ã–π –∑–≤—É–∫ –ø–æ—Å–ª–µ –ø–∞—É–∑—ã
            # –µ—Å–ª–∏ —Ç–∏—à–∏–Ω–∞ != 1 —Å–µ–∫, —Å—á–∏—Ç–∞–µ–º –µ—ë —á–∞—Å—Ç—å—é –∑–≤—É–∫–∞ –∏ –Ω–µ —Ä–µ–∂–µ–º
        silent_run = 0

if current_start < len(y):
    segments.append((current_start, len(y)))

for idx, (s, e) in enumerate(segments):
    seg = y[s:e]
    if len(seg) == 0:
        continue
    out_path = out_dir / f"segment_{idx:03d}.wav"
    sf.write(out_path, seg, sr)



#  üîπ –º–æ–º–µ–Ω—Ç2 : –ø—Ä–æ—Å—Ç–æ –ø–æ—Ä–µ–∑–∞—Ç—å –∞—É–¥–∏–æ –ø–æ 1 —Å–µ–∫

# In[ ]:


import librosa
import soundfile as sf
from pathlib import Path

audio_path = "long_audio.wav"
out_dir = Path("chunks_1s")
out_dir.mkdir(exist_ok=True)

# —á–∏—Ç–∞–µ–º –∞—É–¥–∏–æ
y, sr = librosa.load(audio_path, sr=None, mono=True)

chunk_sec = 1.0
chunk_len = int(chunk_sec * sr)  # 1 —Å–µ–∫—É–Ω–¥–∞ –≤ —Å—ç–º–ø–ª–∞—Ö

# —Ä–µ–∂–µ–º –ø–æ 1 —Å–µ–∫—É–Ω–¥–µ
for i, start in enumerate(range(0, len(y), chunk_len)):
    end = start + chunk_len
    chunk = y[start:end]
    if len(chunk) == 0:
        continue
    out_path = out_dir / f"chunk_{i:04d}.wav"
    sf.write(out_path, chunk, sr)


# # üîπ –ü—É–Ω–∫—Ç 2: –ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∞—É–¥–∏–æ –≤ —Ü–∏—Ñ—Ä–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ

# In[124]:


import os
import librosa
import numpy as np

DATA_DIR = "cats_dogs"
SR = 16000  # –æ–¥–Ω–∞ —á–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ –¥–ª—è –≤—Å–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞


# 1. —Å—ã—Ä–æ–π —Å–∏–≥–Ω–∞–ª (waveform) –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç—Å—è –≤ –≤–µ–∫—Ç–æ—Ä –∞–º–ø–ª–∏—Ç—É–¥ y —Å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π –¥–ª–∏–Ω–æ–π
# 
# –¢–∞–∫–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —É–¥–æ–±–Ω–æ –¥–ª—è –º–æ–¥–µ–ª–µ–π –Ω–∞ —Ç–æ—Ä—á-–∞—É–¥–∏–æ –∏–ª–∏ –ø—Ä–æ—Å—Ç—ã—Ö –±–∞–∑–æ–≤—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤. librosa.load –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–¥–Ω–æ–º–µ—Ä–Ω—ã–π NumPy‚Äë–º–∞—Å—Å–∏–≤ –∞–º–ø–ª–∏—Ç—É–¥ –∏ —á–∞—Å—Ç–æ—Ç—É –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
# 
# - –ü–æ–¥–æ–π–¥—ë—Ç –¥–ª—è PyTorch‚Äë–º–æ–¥–µ–ª–µ–π (1D‚ÄëCNN, RNN), –≥–¥–µ –ø–∞–¥–¥–∏–Ω–≥ –¥–µ–ª–∞–µ—Ç—Å—è —É–∂–µ –≤ DataLoader
# –î–∞–ª—å—à–µ –º–æ–∂–Ω–æ –ø–∏—Å–∞—Ç—å PyTorch‚Äë–¥–∞—Ç–∞—Å–µ—Ç, –∫–æ—Ç–æ—Ä—ã–π –≤ __getitem__ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–¥–∏–Ω –º–∞—Å—Å–∏–≤, –∞ –≤ collate_fn –ø–∞–¥–¥–∏—Ç—å –±–∞—Ç—á –¥–æ –æ–±—â–µ–π –¥–ª–∏–Ω—ã.

# In[137]:


def load_wave(path):
    y, _ = librosa.load(path, sr=SR, mono=True)
    return y.astype(np.float32)

def load_split(split):
    X, y = [], []
    for name, label in [("cat", 0), ("dog", 1)]:
        folder = os.path.join(DATA_DIR, split, name)
        for fname in os.listdir(folder):
            if fname.lower().endswith(".wav"):
                X.append(load_wave(os.path.join(folder, fname)))
                y.append(label)
    return X, np.array(y, dtype=np.int64)

X_train_wave, y_train_wave = load_split("train")
X_test_wave,  y_test_wave  = load_split("test")

print(len(X_train_wave), len(X_test_wave))


# 2. –ú–µ–ª‚Äë—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã (–º–∞—Ç—Ä–∏—Ü—ã —á–∞—Å—Ç–æ—Ç–∞√ó–≤—Ä–µ–º—è)
# –ú–µ–ª‚Äë—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º–∞ ‚Äî —ç—Ç–æ —Å–ø–æ—Å–æ–± –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å –∑–≤—É–∫ –≤ –∫–∞—Ä—Ç–∏–Ω–∫—É, –≥–¥–µ –ø–æ –≤–µ—Ä—Ç–∏–∫–∞–ª–∏ —á–∞—Å—Ç–æ—Ç—ã (–≤ –º–µ–ª‚Äë—à–∫–∞–ª–µ), –ø–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª–∏ –≤—Ä–µ–º—è, –∞ –≤ —è—á–µ–π–∫–∞—Ö —è—Ä–∫–æ—Å—Ç—å = —ç–Ω–µ—Ä–≥–∏—è. –¢–∞–∫–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ—á–µ–Ω—å —É–¥–æ–±–Ω–æ –¥–ª—è 2D‚ÄëCNN
# 
# –ó–≤—É–∫ —Ä–µ–∂—É—Ç –Ω–∞ –∫–æ—Ä–æ—Ç–∫–∏–µ –æ–∫–Ω–∞ (–æ–±—ã—á–Ω–æ 20‚Äì40 –º—Å) –∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–∫–Ω–∞ —Å—á–∏—Ç–∞—é—Ç —Å–ø–µ–∫—Ç—Ä (STFT).‚Äã
# 
# –ó–∞—Ç–µ–º —Å–ø–µ–∫—Ç—Ä –ø—Ä–æ–ø—É—Å–∫–∞—é—Ç —á–µ—Ä–µ–∑ –±–∞–Ω–∫ –º–µ–ª‚Äë—Ñ–∏–ª—å—Ç—Ä–æ–≤ –∏ —Å—É–º–º–∏—Ä—É—é—Ç —ç–Ω–µ—Ä–≥–∏—é –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –¥–∏–∞–ø–∞–∑–æ–Ω–∞—Ö, –Ω–∞–ø—Ä–∏–º–µ—Ä 64 –∏–ª–∏ 128 –ø–æ–ª–æ—Å

# In[ ]:


N_MELS = 64
N_FFT = 1024
HOP_LENGTH = 256

def to_melspec(y):
    S = librosa.feature.melspectrogram(
        y=y,
        sr=SR,
        n_fft=N_FFT,
        hop_length=HOP_LENGTH,
        n_mels=N_MELS
    )              
    S_db = librosa.power_to_db(S, ref=np.max)
    return S_db.astype(np.float32)

def load_split_mels(split):
    X, y = [], []
    for name, label in [("cat", 0), ("dog", 1)]:
        folder = os.path.join(DATA_DIR, split, name)
        for fname in os.listdir(folder):
            if fname.lower().endswith(".wav"):
                path = os.path.join(folder, fname)
                y_wave, _ = librosa.load(path, sr=SR, mono=True)
                X.append(to_melspec(y_wave))
                y.append(label)
    return X, np.array(y, dtype=np.int64)

X_train_spec, y_train_spec = load_split_mels("train")
X_test_spec,  y_test_spec  = load_split_mels("test")

print(len(X_train_spec),len(X_test_spec))
# –ó–¥–µ—Å—å X_train_spec ‚Äî —Å–ø–∏—Å–æ–∫ –º–∞—Ç—Ä–∏—Ü —Ä–∞–∑–Ω—ã—Ö –¥–ª–∏–Ω –ø–æ –≤—Ä–µ–º–µ–Ω–∏ T_i; –≤—ã—Å–æ—Ç–∞ N_MELS —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞


# 3. MFCC‚Äë–ø—Ä–∏–∑–Ω–∞–∫–∏ 
# –ó–¥–µ—Å—å –ø–æ–ª—É—á–∞–µ—Ç—Å—è —á–∏—Å—Ç—ã–π —Ç–∞–±–ª–∏—á–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞, —á—Ç–æ –∏–¥–µ–∞–ª—å–Ω–æ –¥–ª—è SVM, RandomForest, LogisticRegression, MLP

# In[ ]:


N_MFCC = 20

def file_to_mfcc(path):
    y, _ = librosa.load(path, sr=SR, mono=True)
    mfcc = librosa.feature.mfcc(y=y, sr=SR, n_mfcc=N_MFCC)  
    mfcc_mean = mfcc.mean(axis=1)                          
    return mfcc_mean.astype(np.float32)

def load_split_mfcc(split):
    X, y = [], []
    for name, label in [("cat", 0), ("dog", 1)]:
        folder = os.path.join(DATA_DIR, split, name)
        for fname in os.listdir(folder):
            if fname.lower().endswith(".wav"):
                path = os.path.join(folder, fname)
                X.append(file_to_mfcc(path)) 
                y.append(label)
    return np.stack(X), np.array(y, dtype=np.int64)

X_train_mfcc, y_train_mfcc = load_split_mfcc("train")
X_test_mfcc,  y_test_mfcc  = load_split_mfcc("test")


# –æ–±—É—á–∏–º —Å—Ä–∞–∑—É –º–æ–¥–µ–ª—å LG –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞

# In[ ]:


from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline

clf = make_pipeline(
    StandardScaler(),
    LogisticRegression(max_iter=1000)
)

clf.fit(X_train_mfcc, y_train_mfcc)
print("accuracy:", clf.score(X_test_mfcc, y_test_mfcc))


# # 3. –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–ª–∞—Å—Å–æ–≤
# —Ä–∞–∑–±–µ—Ä–µ–º –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ–¥–∞–Ω–Ω—ã—Ö –∫–æ—Ç–æ—Ä—ã–µ –º—ã –ø–æ–ª—É—á–∏–ª–∏ –ø—Ä–∏ MFCC

# –ø–æ—Å—á–∏—Ç–∞–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –ø–∏—Ä—Å–æ–Ω–∞ –º–µ–∂–¥—É –≤—Å–µ–º–∏ –ø–∞—Ä–∞–º–∏ MFCC –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
# –≠—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤–µ–¥—É—Ç —Å–µ–±—è –ø–æ—Ö–æ–∂–µ –∏ –º–æ–≥—É—Ç –±—ã—Ç—å –∏–∑–±—ã—Ç–æ—á–Ω—ã–º–∏

# In[150]:


import pandas as pd

# –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
mfcc_cols = [f"mfcc_{i+1}" for i in range(X_train_mfcc.shape[1])]
df_mfcc = pd.DataFrame(X_train_mfcc, columns=mfcc_cols)

corr_matrix = df_mfcc.corr(method="pearson")
corr_matrix


# —Å–¥–µ–ª–∞–µ–º heatmap

# In[151]:


import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8, 6))
sns.heatmap(corr_matrix, cmap="coolwarm", center=0, square=True)
plt.tight_layout()
plt.show()


# MFCC‚Äë3‚ÄìMFCC‚Äë6 —Å–∏–ª—å–Ω–æ –∫–æ—Ä—Ä–µ–ª–∏—Ä—É—é—Ç —Ç–∞–∫–∂–µ 4-12, 6 - 8. –í –¥–∞–ª—å–Ω–µ–π—à–µ–º –µ—Å–ª–∏ –¥–∞—Ç–∞ –±–æ–ª—å—à–∞—è —Å–ª–∏—à–∫–æ–º –º–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å –æ–¥–∏–Ω –∏–∑ –∫–æ—Ä—Ä–µ–ª–∏—Ä—É—é—â–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

# # üîπ–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã –æ–¥–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞ –ø–æ –¥–≤—É–º –∫–ª–∞—Å—Å–∞–º
# –ü–æ—Å—Ç—Ä–æ–∏–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è mfcc_1 –∏ mfcc_2 –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –¥–ª—è –∫–æ—Ç–æ–≤ –∏ —Å–æ–±–∞–∫. –°–º–æ—Ç—Ä–∏–º, –Ω–∞—Å–∫–æ–ª—å–∫–æ —Å–∏–ª—å–Ω–æ —Ä–∞–∑—ä–µ–∑–∂–∞—é—Ç—Å—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è; –µ—Å–ª–∏ –ø–æ—á—Ç–∏ –Ω–µ –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è, –ø—Ä–∏–∑–Ω–∞–∫ —Ö–æ—Ä–æ—à–æ –æ—Ç–ª–∏—á–∞–µ—Ç –∫–ª–∞—Å—Å—ã
# 
# –ï—Å–ª–∏ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã –ø–æ—á—Ç–∏ –ª–µ–∂–∞—Ç –¥—Ä—É–≥ –Ω–∞ –¥—Ä—É–≥–µ (–ø–æ—Ö–æ–∂–∞—è —Ñ–æ—Ä–º–∞ –∏ –æ–±–ª–∞—Å—Ç—å –∑–Ω–∞—á–µ–Ω–∏–π), –ø—Ä–∏–∑–Ω–∞–∫ –º–∞–ª–æ –ø–æ–º–æ–≥–∞–µ—Ç –æ—Ç–ª–∏—á–∞—Ç—å —Å–∏–≥–Ω–∞–ª—ã –∏ –¥–∞—ë—Ç —Å–ª–∞–±—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏

# In[149]:


def plot_hist_for_feature(idx):
    name = mfcc_cols[idx]
    cats = X_train_mfcc[y_train_mfcc == 0, idx]
    dogs = X_train_mfcc[y_train_mfcc == 1, idx]

    plt.figure(figsize=(6, 4))
    plt.hist(cats, bins=20, alpha=0.6, label="cat", density=True)
    plt.hist(dogs, bins=20, alpha=0.6, label="dog", density=True)
    plt.xlabel(name)
    plt.legend()
    plt.tight_layout()
    plt.show()

# –ø—Ä–∏–º–µ—Ä: –ø–µ—Ä–≤—ã–µ –¥–≤–∞ MFCC
plot_hist_for_feature(0)  # mfcc_1
plot_hist_for_feature(1)  # mfcc_2

