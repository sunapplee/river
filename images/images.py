#!/usr/bin/env python
# coding: utf-8

#  # üîπ 1) –Ω–∞—á–∞–ª—å–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π

# 1. –∏–º–ø–æ—Ä—Ç—ã –±–∏–±–ª–∏–æ—Ç–µ–∫

# In[1]:


import os
from pathlib import Path
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.svm import SVC

import torch
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, models


# 2. –ø—Ä–∏–≤–µ–¥–µ–º –∫–∞—Ä—Ç–∏–Ω–∫–∏ –∫ –æ–¥–Ω–æ–º—É –≤–∏–¥—É –∏ —Ñ–æ—Ä–º–∞—Ç—É —Ç–µ–Ω–∑–æ—Ä–∞

# In[2]:


from torchvision import transforms

basic_tfms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

from torchvision import datasets

train_ds = datasets.ImageFolder("data_fruits/train", transform=basic_tfms)
val_ds   = datasets.ImageFolder("data_fruits/val",   transform=basic_tfms)
test_ds  = datasets.ImageFolder("data_fruits/test",  transform=basic_tfms)


# 3. —Å–æ—â–¥–∞–µ–º ImageFolder, –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–µ–Ω, —á—Ç–æ–±—ã –Ω–µ –ø–∏—Å–∞—Ç—å —Å–≤–æ–π –∫–æ–¥ –æ–±—Ö–æ–¥–∞ –ø–∞–ø–æ–∫
# ImageFolder:
# - —Å–º–æ—Ç—Ä–∏—Ç –Ω–∞ –ø–æ–¥–ø–∞–ø–∫–∏ –≤ train/val/test,
# - —Å—á–∏—Ç–∞–µ—Ç –∫–∞–∂–¥—É—é –ø–æ–¥–ø–∞–ø–∫—É –æ—Ç–¥–µ–ª—å–Ω—ã–º –∫–ª–∞—Å—Å–æ–º,
# - –∫–∞–∂–¥–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –¥–∞—ë—Ç –Ω–æ–º–µ—Ä –∫–ª–∞—Å—Å–∞

# In[3]:


from torchvision import datasets

train_ds = datasets.ImageFolder(root="data_fruits/train", transform=basic_tfms)
val_ds   = datasets.ImageFolder(root="data_fruits/val",   transform=basic_tfms)
test_ds  = datasets.ImageFolder(root="data_fruits/test",  transform=basic_tfms)


# 4. DataLoader

# In[4]:


from torch.utils.data import DataLoader

train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)
val_dl   = DataLoader(val_ds, batch_size=32, shuffle=False)
test_dl  = DataLoader(test_ds, batch_size=32, shuffle=False)


# # üîπ 2) –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π ML –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
# 
# 1 –≤–∞—Ä–∏–∞–Ω—Ç 
# 1. –ü—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É –≤ —á–∏—Å–ª–æ–≤–æ–π –≤–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
# —Ç.–µ
#     - –ø–µ—Ä–µ–≤–æ–¥–∏–º –∫–∞—Ä—Ç–∏–Ω–∫—É –≤ RGB;
#     - —É–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä (–¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏);
#     - —Å—á–∏—Ç–∞–µ–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É –ø–æ –∫–∞–∂–¥–æ–º—É –∫–∞–Ω–∞–ª—É (R, G, B);
#     - —Å–æ–µ–¥–∏–Ω—è–µ–º —Ç—Ä–∏ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã –≤ –æ–¥–∏–Ω –≤–µ–∫—Ç–æ—Ä.
# 2. –û–±—É—á–∏—Ç—å –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, SVM) –Ω–∞ —ç—Ç–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö.
# 3. –ü–æ–ª—É—á–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ (accuracy, precision, recall, F1).
# 
# 2 –≤–∞—Ä–∏–∞–Ω—Ç
# –ø—Ä–æ—Å—Ç–æ –±–æ–ª—å—à–µ —Ä–∞–∑–º–µ—Ä + flatten

# 1 –≤–∞—Ä–∏–∞–Ω—Ç

# In[5]:


class_names = sorted([p.name for p in Path("data_fruits/train").iterdir() if p.is_dir()])

def img_features1(path, bins=16):
    """
    –ò–∑ –æ–¥–Ω–æ–π –∫–∞—Ä—Ç–∏–Ω–∫–∏ –¥–µ–ª–∞–µ–º –≤–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
    - –ø–µ—Ä–µ–≤–æ–¥–∏–º –∫–∞—Ä—Ç–∏–Ω–∫—É –≤ RGB;
    - —É–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä (–¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏);
    - —Å—á–∏—Ç–∞–µ–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É –ø–æ –∫–∞–∂–¥–æ–º—É –∫–∞–Ω–∞–ª—É (R, G, B);
    - —Å–æ–µ–¥–∏–Ω—è–µ–º —Ç—Ä–∏ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã –≤ –æ–¥–∏–Ω –≤–µ–∫—Ç–æ—Ä.
    - –¥–æ–±–∞–≤–ª—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –ø–æ –∫–∞–∂–¥–æ–º—É –∫–∞–Ω–∞–ª—É (–µ—â—ë 6 —á–∏—Å–µ–ª)
    """
    # 1) RGB
    img = Image.open(path).convert("RGB")

    # 2) —É–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä
    img = img.resize((128, 128))

    # 3) –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –ø–æ –∫–∞–Ω–∞–ª–∞–º
    arr = np.array(img)
    hist_list = []
    for ch in range(3): 
        channel = arr[..., ch]
        hist, _ = np.histogram(
            channel,
            bins=bins,
            range=(0, 256),
            density=True
        )
        hist_list.append(hist)


    means = arr.mean(axis=(0, 1))
    stds  = arr.std(axis=(0, 1))

    # 4) –æ–¥–∏–Ω –æ–±—â–∏–π –≤–µ–∫—Ç–æ—Ä
    features = np.concatenate(hist_list + [means, stds])
    return features


# 2 –≤–∞—Ä–∏–∞–Ω—Ç

# In[6]:


class_names = sorted([p.name for p in Path("data_fruits/train").iterdir() if p.is_dir()])
train_dir = Path("data_fruits/train")

def img_features2(path):
    """
    –ü—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –∫–∞—Ä—Ç–∏–Ω–∫–∏:
    - RGB
    - —É–º–µ–Ω—å—à–∞–µ–º –¥–æ 32x32
    - —Ä–∞—Å–ø–ª—é—â–∏–≤–∞–µ–º –≤ –æ–¥–∏–Ω –≤–µ–∫—Ç–æ—Ä (32*32*3 = 3072 —á–∏—Å–ª–∞)
    """
    img = Image.open(path).convert("RGB")
    img = img.resize((32, 32))
    arr = np.array(img) / 255.0
    return arr.flatten()


# –¥–µ–ª–∞–µ–º –º–∞—Ç—Ä–∏—Ü—ã x –∏ y –¥–ª—è 2 –≤–∞—Ä–∏–∞–Ω—Ç–∞

# In[7]:


X, y = [], []

for cls_idx, cls in enumerate(class_names):
    folder = train_dir / cls
    for name in os.listdir(folder):
        if name.lower().endswith((".jpg", ".jpeg", ".png")):
            X.append(img_features2(folder / name))
            y.append(cls_idx)

X = np.array(X)
y = np.array(y)


# –¥–µ–ª–∞–µ–º –º–∞—Ç—Ä–∏—Ü—ã x –∏ y –¥–ª—è 1 –≤–∞—Ä–∏–∞–Ω—Ç–∞

# In[8]:


X, y = [], []

for cls_idx, cls in enumerate(class_names):
    folder = Path("data_fruits/train") / cls
    for name in os.listdir(folder):
        if name.lower().endswith((".jpg", ".jpeg", ".png")):
            path = folder / name
            X.append(img_features1(path))  # –ø—Ä–∏–∑–Ω–∞–∫–∏
            y.append(cls_idx)  # –Ω–æ–º–µ—Ä –∫–ª–∞—Å—Å–∞

X = np.array(X)
y = np.array(y)


# –¥–µ–ª–∏–º –Ω–∞ train –∏ val

# In[9]:


from sklearn.model_selection import train_test_split

X_tr, X_val, y_tr, y_val = train_test_split(
    X, y,
    test_size=0.2,
    stratify=y,
    random_state=42
)


# –æ–±—É—á–∏–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏

# 1. –ª–æ–≥–∏—Å—Ç–∏—á—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è

# In[ ]:


from sklearn.metrics import classification_report
from sklearn.linear_model import LogisticRegression

log_reg = LogisticRegression(max_iter=1000)
log_reg.fit(X_tr, y_tr)

y_pred_lr = log_reg.predict(X_val)
print(classification_report(y_val, y_pred_lr, target_names=class_names))


# —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –æ—á–µ–Ω—å —Ç–∫ –¥–∞–Ω–Ω—ã—Ö –æ—á–µ–Ω—å –º–∞–ª–æ

# 2. SVM

# In[ ]:


from sklearn.svm import SVC

svm_clf = SVC(kernel="rbf", C=5, gamma="scale")
svm_clf.fit(X_tr, y_tr)

y_pred_svm = svm_clf.predict(X_val)
print(classification_report(y_val, y_pred_svm, target_names=class_names))


# 3. random forest

# In[ ]:


from sklearn.ensemble import RandomForestClassifier

rf_clf = RandomForestClassifier(
    n_estimators=200,
    random_state=42,
    n_jobs=-1
)
rf_clf.fit(X_tr, y_tr)

y_pred_rf = rf_clf.predict(X_val)
print(classification_report(y_val, y_pred_rf, target_names=class_names))


# üîπ 3) –ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ 
# 
# –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ ResNet18

# - –≤—ã–±–∏—Ä–∞–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (`device`);
# - —Å—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤ (`num_classes`);
# - –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω—É–∂–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏.

# In[ ]:


import torch
from torch import nn, optim
from torchvision import models
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix

# device: –∫—É–¥–∞ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –º–æ–¥–µ–ª—å –∏ –¥–∞–Ω–Ω—ã–µ (cuda, –µ—Å–ª–∏ –µ—Å—Ç—å GPU, –∏–Ω–∞—á–µ cpu)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# num_classes: —Å–∫–æ–ª—å–∫–æ —É –Ω–∞—Å —Ä–∞–∑–Ω—ã—Ö —Ñ—Ä—É–∫—Ç–æ–≤ (–∫–ª–∞—Å—Å–æ–≤)
num_classes = len(class_names)


# –°–æ–∑–¥–∞—ë–º ResNet18 (–º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–∞–∫–∂–µ ResNet50 / ResNet101 )

# In[16]:


# —Å–æ–∑–¥–∞—ë–º ResNet18 –±–µ–∑ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –≤–µ—Å–æ–≤
resnet = models.resnet18(weights=None)

#resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT) - –æ–±—É—á–µ–Ω–∏–µ —Å –≤–µ—Å–∞–º–∏(–º–æ–π –Ω–æ—É—Ç –ø—Ä–æ—Å—Ç–æ –Ω–µ —Ç—è–Ω–µ—Ç)


# –ú–µ–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π –ø–æ–¥ –Ω–∞—à–∏ –∫–ª–∞—Å—Å—ã
# 
# - `resnet.fc` ‚Äî –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π.
# - –£ –Ω–µ–≥–æ –µ—Å—Ç—å –≤—Ö–æ–¥–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å `in_features`.
# - –ó–∞–º–µ–Ω—è–µ–º –µ–≥–æ –Ω–∞ `nn.Linear(in_features, num_classes)`, —á—Ç–æ–±—ã –º–æ–¥–µ–ª—å –º–æ–≥–ª–∞ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞—à–∏ –∫–ª–∞—Å—Å—ã.

# In[17]:


in_features = resnet.fc.in_features
resnet.fc = nn.Linear(in_features, num_classes)


# –ü–µ—Ä–µ–Ω–æ—Å –º–æ–¥–µ–ª–∏ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–±—É—á–µ–Ω–∏—è
# 
# - –ü–µ—Ä–µ–Ω–æ—Å–∏–º –º–æ–¥–µ–ª—å –Ω–∞ `device`.
# - –ó–∞–¥–∞—ë–º:
#   - `criterion` ‚Äî —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å (CrossEntropyLoss –¥–ª—è –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–æ–π –∑–∞–¥–∞—á–∏).
#   - `optimizer_resnet` ‚Äî –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä Adam —Å –º–∞–ª–µ–Ω—å–∫–∏–º —à–∞–≥–æ–º –æ–±—É—á–µ–Ω–∏—è.

# In[18]:


# –ø–µ—Ä–µ–Ω–æ—Å–∏–º –º–æ–¥–µ–ª—å –Ω–∞ GPU/CPU
resnet = resnet.to(device)

# —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å: —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –ª–æ–≥–∏—Ç—ã –∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –º–µ—Ç–∫–∏
criterion = nn.CrossEntropyLoss()

# –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä: Adam, –æ–±—É—á–∞–µ–º –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
optimizer_resnet = optim.Adam(
    resnet.parameters(),
    lr=1e-4,
    weight_decay=1e-4,   # —ç—Ç–æ L2‚Äë—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è, –æ–Ω–∞ —à—Ç—Ä–∞—Ñ—É–µ—Ç —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ –≤–µ—Å–∞ –∏ –ø–æ–º–æ–≥–∞–µ—Ç –±–æ—Ä–æ—Ç—å—Å—è —Å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º
)



# –æ–±—É—á–∞–µ–º —ç–ø–æ—Ö—É
# –ù–∞ –≤—Ö–æ–¥:
# - `model` ‚Äî –Ω–∞—à–∞ ResNet18;
# - `loader` ‚Äî train_dl (–±–∞—Ç—á–∏ –∫–∞—Ä—Ç–∏–Ω–æ–∫ –∏ –º–µ—Ç–æ–∫);
# - `optimizer` ‚Äî –æ–±—ä–µ–∫—Ç Adam.
# 
# –ü—Ä–æ—Ü–µ—Å—Å:
# 1. –ü–µ—Ä–µ–≤–æ–¥–∏–º –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è `model.train()`.
# 2. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –±–∞—Ç—á–∞:
#    - –ø–µ—Ä–µ–Ω–æ—Å–∏–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ `device`;
#    - –æ–±–Ω—É–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã;
#    - —Å—á–∏—Ç–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (`logits`);
#    - —Å—á–∏—Ç–∞–µ–º loss;
#    - —Å—á–∏—Ç–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã (`backward`);
#    - –¥–µ–ª–∞–µ–º —à–∞–≥ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ (`step`);
#    - –∫–æ–ø–∏–º loss –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–µ—Ä–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤.
# 3. –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ä–µ–¥–Ω–∏–π loss –∏ accuracy –ø–æ –≤—Å–µ–π —ç–ø–æ—Ö–µ

# In[19]:


def train_one_epoch(model, loader, optimizer):
    model.train()     

    total_loss = 0.0             
    total_correct = 0        
    total = 0                        

    for images, labels in loader:
        # –ø–µ—Ä–µ–Ω–æ—Å–∏–º –∫–∞—Ä—Ç–∏–Ω–∫–∏ –∏ –º–µ—Ç–∫–∏ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        images = images.to(device)
        labels = labels.to(device)

        # —à–∞–≥ 1: –æ–±–Ω—É–ª—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
        optimizer.zero_grad()

        # —à–∞–≥ 2: –ø—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ (forward)
        logits = model(images)

        # —à–∞–≥ 3: —Å—á–∏—Ç–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å
        loss = criterion(logits, labels)

        # —à–∞–≥ 4: –æ–±—Ä–∞—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –æ—à–∏–±–∫–∏
        loss.backward()

        # —à–∞–≥ 5: –æ–±–Ω–æ–≤–ª—è–µ–º –≤–µ—Å–∞
        optimizer.step()

        # —Å—á–∏—Ç–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –±–∞—Ç—á—É
        batch_size = images.size(0)
        total_loss += loss.item() * batch_size

        # –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å = –∏–Ω–¥–µ–∫—Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –ª–æ–≥–∏—Ç–∞
        preds = logits.argmax(1)
        total_correct += (preds == labels).sum().item()
        total += batch_size

    # —Å—Ä–µ–¥–Ω–∏–π loss –∏ accuracy –ø–æ —ç–ø–æ—Ö–µ
    avg_loss = total_loss / total
    avg_acc = total_correct / total
    return avg_loss, avg_acc


# –æ—Ü–µ–Ω–∫–∞
# –ù–∞ –≤—Ö–æ–¥:
# - `model` ‚Äî ResNet18;
# - `loader` ‚Äî val_dl –∏–ª–∏ test_dl.
# 
# –ü—Ä–æ—Ü–µ—Å—Å:
# 1. –ü–µ—Ä–µ–≤–æ–¥–∏–º –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏ `model.eval()`.
# 2. –û—Ç–∫–ª—é—á–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã `torch.no_grad()`.
# 3. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –±–∞—Ç—á–∞:
#    - —Å—á–∏—Ç–∞–µ–º loss –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è;
#    - –∫–æ–ø–∏–º loss –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–µ—Ä–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤;
#    - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –º–µ—Ç–∫–∏ –∏ –≤—Å–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è.
# 4. –í–æ–∑–≤—Ä–∞—â–∞–µ–º:
#    - —Å—Ä–µ–¥–Ω–∏–π loss,
#    - accuracy,
#    - –º–∞—Å—Å–∏–≤ –≤—Å–µ—Ö –∏—Å—Ç–∏–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ `y_true`,
#    - –º–∞—Å—Å–∏–≤ –≤—Å–µ—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π `y_pred`

# In[20]:


def evaluate(model, loader):
    model.eval()      
    total_loss = 0.0
    total_correct = 0
    total = 0

    all_labels = []
    all_preds = []

    with torch.no_grad(): 
        for images, labels in loader:
            images = images.to(device)
            labels = labels.to(device)

            logits = model(images)
            loss = criterion(logits, labels)

            batch_size = images.size(0)
            total_loss += loss.item() * batch_size

            preds = logits.argmax(1)
            total_correct += (preds == labels).sum().item()
            total += batch_size

            # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –æ—Ç—á—ë—Ç–æ–≤
            all_labels.append(labels.cpu().numpy())
            all_preds.append(preds.cpu().numpy())

    avg_loss = total_loss / total
    avg_acc = total_correct / total
    y_true = np.concatenate(all_labels)
    y_pred = np.concatenate(all_preds)
    return avg_loss, avg_acc, y_true, y_pred


# –û–±—É—á–µ–Ω–∏–µ ResNet18 –ø–æ —ç–ø–æ—Ö–∞–º
# 
# - `num_epochs` ‚Äî —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –ø—Ä–æ—Ö–æ–¥–∏–º –ø–æ train_dl.
# - –ù–∞ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–µ:
#   - —Å—á–∏—Ç–∞–µ–º `train_loss`, `train_acc` –Ω–∞ train_dl;
#   - —Å—á–∏—Ç–∞–µ–º `val_loss`, `val_acc` –Ω–∞ val_dl;
#   - –ø–µ—á–∞—Ç–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è.

# In[21]:


num_epochs = 5  # –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ

for epoch in range(num_epochs):
    train_loss, train_acc = train_one_epoch(resnet, train_dl, optimizer_resnet)
    val_loss, val_acc, _, _ = evaluate(resnet, val_dl)

    print(
        f"[ResNet] Epoch {epoch+1}/{num_epochs} | "
        f"train_loss={train_loss:.4f}, train_acc={train_acc:.3f} | "
        f"val_loss={val_loss:.4f}, val_acc={val_acc:.3f}"
    )


# –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ
# 
# - —Å—á–∏—Ç–∞–µ–º `test_loss` –∏ `test_acc` –Ω–∞ `test_dl`;
# - —Å—Ç—Ä–æ–∏–º `classification_report` (precision, recall, F1 –ø–æ –∫–∞–∂–¥–æ–º—É –∫–ª–∞—Å—Å—É);
# - –ø–æ–ª—É—á–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É –æ—à–∏–±–æ–∫ `confusion_matrix`.

# In[25]:


test_loss, test_acc, y_true_res, y_pred_res = evaluate(resnet, test_dl)

print("ResNet18 test_loss:", test_loss)
print("ResNet18 test_acc :", test_acc)

print(classification_report(
    y_true_res,
    y_pred_res,
    target_names=class_names,
    zero_division=0
))

cm_resnet = confusion_matrix(y_true_res, y_pred_res)
cm_resnet


# –ø–ª–æ—Ö–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–∫ –Ω–µ—Ç –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –≤–µ—Å–æ–≤

# # –¢–∞–∫–∂–µ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å  EfficientNet-B0 –∏–ª–∏ Vision Transformer ViT-B/16

# # üîπ –ú–µ—Ç—Ä–∏–∫–∏ 

# In[26]:


from sklearn.metrics import (
    classification_report,
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
)

# accuracy 
acc = accuracy_score(y_true_res, y_pred_res)
print("Accuracy:", acc)

# macro precision/recall/F1
prec = precision_score(y_true_res, y_pred_res, average="macro", zero_division=0)
rec  = recall_score(y_true_res, y_pred_res, average="macro", zero_division=0)
f1   = f1_score(y_true_res, y_pred_res, average="macro", zero_division=0)

print("Macro precision:", prec)
print("Macro recall   :", rec)
print("Macro F1       :", f1)

# –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á—ë—Ç –ø–æ –∫–∞–∂–¥–æ–º—É –∫–ª–∞—Å—Å—É
print(classification_report(y_true_res, y_pred_res, target_names=class_names, zero_division=0))


# - accuracy_score –¥–∞—ë—Ç –æ–±—â—É—é –¥–æ–ª—é –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤.
# 
# - precision_score/recall_score/f1_score —Å average="macro" –¥–∞—é—Ç —Å—Ä–µ–¥–Ω–µ–µ –ø–æ –∫–ª–∞—Å—Å–∞–º.
# 
# - –î–ª—è **accuracy, precision, recall, F1**: –≤—Å–µ–≥–¥–∞ **—á–µ–º –≤—ã—à–µ, —Ç–µ–º –ª—É—á—à–µ** 

# # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ñ—Ä—É–∫—Ç–æ–≤

# In[24]:


torch.save(resnet.state_dict(), 'fruit_model.pth')


# ###

# # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è
# 
# –ß–∞—Å—Ç–æ –Ω–∞ —á–µ–º–ø–∏–æ–Ω–∞—Ç–∞—Ö –ø—Ä–æ—Å—è—Ç –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞—Ç—å –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π —Å –ø–æ–º–æ—â—å—é AirFlow. 
# 
# –°–æ–∑–¥–∞–¥–∏–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω–æ–≤—ã—Ö –∫–ª–∞—Å—Å–æ–≤, –∫–æ—Ç–æ—Ä—É—é –º–æ–∂–Ω–æ –±—É–¥–µ—Ç –ø–µ—Ä–µ–Ω–µ—Å—Ç–∏ –≤ Airflow –∏–ª–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –≤ –±—É–¥—É—â–µ–º.

# In[28]:


def fine_tuning_fruit(new_data: DataLoader) -> None:
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å, –ø–µ—Ä–µ–Ω–æ—Å–∏–º –Ω–∞ gpu –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    model = models.resnet18(weights=None)
    model.fc = nn.Linear(model.fc.in_features, 9)
    model.load_state_dict(torch.load("fruit_model.pth"))
    model.to(device)

    # –°–æ–∑–¥–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –º–æ–¥–µ–ª–∏
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
    criterion = torch.nn.CrossEntropyLoss()

    # –ë–µ—Ä–µ–º —É–∂–µ –Ω–∞–ø–∏—Å–∞–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
    for epoch in range(5):
        loss, acc = train_one_epoch(model, new_data, optimizer)
        print(f"{epoch}: loss={loss:.4f}, acc={acc:.4f}")


    # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
    test_ds  = datasets.ImageFolder("data_fruits/test",  transform=basic_tfms)
    test_dl  = DataLoader(test_ds, batch_size=32, shuffle=False)

    test_loss, test_acc, y_true_res, y_pred_res = evaluate(model, test_dl)

    prec = precision_score(y_true_res, y_pred_res, average="macro", zero_division=0)
    rec  = recall_score(y_true_res, y_pred_res, average="macro", zero_division=0)
    f1   = f1_score(y_true_res, y_pred_res, average="macro", zero_division=0)
    acc = accuracy_score(y_true_res, y_pred_res)
    metrics = {
    "accuracy": acc,
    "macro_precision": prec,
    "macro_recall": rec,
    "macro_f1": f1
    }

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—É—é –º–æ–¥–µ–ª—å
    torch.save(model.state_dict(), "fruit_model.pth")

    return metrics




# ## –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é

# In[29]:


from torch.utils.data import Dataset

class SimpleImageDataset(Dataset):
    def __init__(self, image_paths, labels, transform=None):
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img = Image.open(self.image_paths[idx]).convert("RGB")
        label = self.labels[idx]

        if self.transform:
            img = self.transform(img)

        return img, label


# In[30]:


new_images = ["coconut.jpg", ]
new_labels = [3, ]

dataset = SimpleImageDataset(new_images, new_labels, transform=basic_tfms)
fine_tuning_loader = DataLoader(dataset, batch_size=4, shuffle=True)


# In[31]:


fine_tuning_fruit(fine_tuning_loader)


# #### –î–∞–Ω–Ω—ã–π —Å–ø–æ—Å–æ–± –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ –¥–æ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏, –Ω–æ–≤—ã–π –∫–ª–∞—Å—Å —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º –Ω–µ –¥–æ–±–∞–≤–∏—Ç—å. –ï–≥–æ –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤ –ø—Ä–æ—Å—Ç—ã—Ö —Å–ª—É—á–∞—è—Ö –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.
# 
# #### –ù–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π –∫–ª–∞—Å—Å, —Ç–æ –Ω—É–∂–Ω–æ –¥–æ–±–∞–≤–ª—è—Ç—å –¥–∞–Ω–Ω—ã–µ –∫ –æ—Å–Ω–æ–≤–Ω–æ–º—É –Ω–∞–±–æ—Ä—É –∏ –ø–µ—Ä–µ–æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª—å ResNet .

# ###

# # –§—É–Ω–∫—Ü–∏—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω–æ–≤–æ–≥–æ –∫–ª–∞—Å—Å–∞.

# –í–∞–∂–Ω–æ! –í –ø–∞–ø–∫–µ data_fruits –¥–æ–±–∞–≤–∏–ª–∏ –Ω–æ–≤—ã–π —Ç–∞—Ä–≥–µ—Ç coconut, –∫—É–¥–∞ –¥–æ–±–∞–≤–∏–ª–∏ –Ω–∞—à–µ –Ω–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.

# In[32]:


get_ipython().system('ls data_fruits/train/')


# In[40]:


def retrain_model(num_epochs=5):
    basic_tfms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    ])

    train_ds = datasets.ImageFolder("data_fruits/train", transform=basic_tfms)
    val_ds   = datasets.ImageFolder("data_fruits/val",   transform=basic_tfms)
    test_ds  = datasets.ImageFolder("data_fruits/test",  transform=basic_tfms)

    train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)
    val_dl   = DataLoader(val_ds, batch_size=32, shuffle=False)
    test_dl  = DataLoader(test_ds, batch_size=32, shuffle=False)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    class_names = sorted([p.name for p in Path("data_fruits/train").iterdir() if p.is_dir()])
    num_classes = len(class_names)

    model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
    in_features = model.fc.in_features
    model.fc = nn.Linear(in_features, num_classes)

    # –ø–µ—Ä–µ–Ω–æ—Å–∏–º –º–æ–¥–µ–ª—å –Ω–∞ GPU/CPU
    model = model.to(device)

    criterion = nn.CrossEntropyLoss()

    optimizer = optim.Adam(
        model.parameters(),
        lr=1e-4,
        weight_decay=1e-4,
    )

    for epoch in range(num_epochs):
        train_loss, train_acc = train_one_epoch(model, train_dl, optimizer)
        val_loss, val_acc, _, _ = evaluate(model, val_dl)

        print(
            f"[ResNet] Epoch {epoch+1}/{num_epochs} | "
            f"train_loss={train_loss:.4f}, train_acc={train_acc:.3f} | "
            f"val_loss={val_loss:.4f}, val_acc={val_acc:.3f}"
        )

    test_loss, test_acc, y_true_res, y_pred_res = evaluate(model, test_dl)

    prec = precision_score(y_true_res, y_pred_res, average="macro", zero_division=0)
    rec  = recall_score(y_true_res, y_pred_res, average="macro", zero_division=0)
    f1   = f1_score(y_true_res, y_pred_res, average="macro", zero_division=0)
    acc = accuracy_score(y_true_res, y_pred_res)
    metrics = {
    "accuracy": acc,
    "macro_precision": prec,
    "macro_recall": rec,
    "macro_f1": f1
    }

    report = classification_report(
    y_true_res,
    y_pred_res,
    target_names=class_names,
    zero_division=0
    )

    torch.save(model.state_dict(), "fruit_model.pth")

    return metrics, report


# In[41]:


metrics, report = retrain_model(num_epochs=3)

print(metrics)


# In[42]:


print(report)


# –ö–∞–∫ –≤–∏–¥–∏–º –∏–∑ –≤—ã–≤–æ–¥–∞, —É –Ω–∞—Å –¥–æ–±–∞–≤–∏–ª—Å—è –Ω–æ–≤—ã–π –∫–ª–∞—Å—Å coconut fruit.
