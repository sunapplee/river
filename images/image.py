#!/usr/bin/env python
# coding: utf-8

# #  –ü–æ–ª–Ω—ã–π –æ—Ç—á—ë—Ç: –†–∞–±–æ—Ç–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –≤ –∑–∞–¥–∞—á–∞—Ö –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞  
# *–î–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∫ —á–µ–º–ø–∏–æ–Ω–∞—Ç—É  (–Ω–∞ –ø—Ä–∏–º–µ—Ä–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ ¬´Dog Breed Image Dataset¬ª)*
# 

# ## üîπ –°–ø–æ—Å–æ–±—ã –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞
# 
# –ü–µ—Ä–µ–¥ —Ç–µ–º –∫–∞–∫ –ø—Ä–∏—Å—Ç—É–ø–∏—Ç—å –∫ –∑–∞–≥—Ä—É–∑–∫–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –≤–∞–∂–Ω–æ –ø–æ–Ω—è—Ç—å, **–∫–∞–∫ –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–Ω—ã –¥–∞–Ω–Ω—ã–µ**. –û—Ç —ç—Ç–æ–≥–æ –∑–∞–≤–∏—Å–∏—Ç —Å–ø–æ—Å–æ–± –∏—Ö —Å—á–∏—Ç—ã–≤–∞–Ω–∏—è –∏ –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏. –°—É—â–µ—Å—Ç–≤—É–µ—Ç –¥–≤–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–∞, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ.
# 

# ###  –°–ø–æ—Å–æ–± 1: –ö–∞–∂–¥–∞—è –ø–∞–ø–∫–∞ ‚Äî –æ—Ç–¥–µ–ª—å–Ω—ã–π –∫–ª–∞—Å—Å (–æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç)
# 
# –≠—Ç–æ **–Ω–∞–∏–±–æ–ª–µ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω—ã–π –∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π —Å–ø–æ—Å–æ–±** –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. 
# 
# **–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –≤—ã–≥–ª—è–¥–∏—Ç —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º:**
# ```
# dog_breeds/
# ‚îú‚îÄ‚îÄ Labrador/
# ‚îÇ   ‚îú‚îÄ‚îÄ 001.jpg
# ‚îÇ   ‚îú‚îÄ‚îÄ 002.jpg
# ‚îÇ   ‚îî‚îÄ‚îÄ ...
# ‚îú‚îÄ‚îÄ Beagle/
# ‚îÇ   ‚îú‚îÄ‚îÄ 101.jpg
# ‚îÇ   ‚îî‚îÄ‚îÄ ...
# ‚îú‚îÄ‚îÄ Poodle/
# ‚îÇ   ‚îî‚îÄ‚îÄ ...
# ‚îî‚îÄ‚îÄ ...
# ```
# 
# –í —ç—Ç–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ:
# - –ù–∞–∑–≤–∞–Ω–∏–µ –∫–∞–∂–¥–æ–π –ø–æ–¥–ø–∞–ø–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, `Labrador`) **—è–≤–ª—è–µ—Ç—Å—è –º–µ—Ç–∫–æ–π –∫–ª–∞—Å—Å–∞**.
# - –í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –Ω–∞—Ö–æ–¥—è—â–∏–µ—Å—è –≤–Ω—É—Ç—Ä–∏ —ç—Ç–æ–π –ø–æ–¥–ø–∞–ø–∫–∏, **–æ—Ç–Ω–æ—Å—è—Ç—Å—è –∫ –¥–∞–Ω–Ω–æ–º—É –∫–ª–∞—Å—Å—É**.
# - –ù–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π ‚Äî —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–æ–∫ —Å–∞–º–∞ –ø–æ —Å–µ–±–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å—é –Ω–µ–æ–±—Ö–æ–¥–∏–º—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.
# 
# **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ —ç—Ç–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞:**
# - –ü—Ä–æ—Å—Ç–æ—Ç–∞ –∏ –∏–Ω—Ç—É–∏—Ç–∏–≤–Ω–∞—è –ø–æ–Ω—è—Ç–Ω–æ—Å—Ç—å.
# - –ü—Ä—è–º–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –≤–µ–¥—É—â–∏–º–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞–º–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, —Ç–∞–∫–∏–º–∏ –∫–∞–∫ PyTorch (`torchvision.datasets.ImageFolder`), TensorFlow (`tf.keras.utils.image_dataset_from_directory`) –∏ YOLO (Ultralytics).
# - –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∏—Å–∫ –æ—à–∏–±–æ–∫ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö.
# 

# ###  –°–ø–æ—Å–æ–± 2: –ú–µ—Ç–∫–∞ –∫–ª–∞—Å—Å–∞ —É–∫–∞–∑–∞–Ω–∞ –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
# 
# –í –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Å–ª—É—á–∞—è—Ö, –æ—Å–æ–±–µ–Ω–Ω–æ –≤ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∏–ª–∏ –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö, –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –º–æ–≥—É—Ç –Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –≤ **–æ–¥–Ω–æ–π –æ–±—â–µ–π –ø–∞–ø–∫–µ**, –∞ –º–µ—Ç–∫–∞ –∫–ª–∞—Å—Å–∞ **–∫–æ–¥–∏—Ä—É–µ—Ç—Å—è –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞**.
# 
# **–ü—Ä–∏–º–µ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã:**
# ```
# images/
# ‚îú‚îÄ‚îÄ Labrador_001.jpg
# ‚îú‚îÄ‚îÄ Beagle_002.jpg
# ‚îú‚îÄ‚îÄ Poodle_003.jpg
# ‚îî‚îÄ‚îÄ ...
# ```
# 
# –ó–¥–µ—Å—å:
# - –ö–ª–∞—Å—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä, `Labrador`) —è–≤–ª—è–µ—Ç—Å—è **–ø–µ—Ä–≤–æ–π —á–∞—Å—Ç—å—é –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞**, –æ—Ç–¥–µ–ª—ë–Ω–Ω–æ–π –æ—Ç –æ—Å—Ç–∞–ª—å–Ω–æ–≥–æ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ —Å–∏–º–≤–æ–ª–æ–º –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏—è `_`.
# - –ß—Ç–æ–±—ã –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –º–µ—Ç–∫—É, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ **–ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–º—è —Ñ–∞–π–ª–∞** –∏ –∏–∑–≤–ª–µ—á—å –∏–∑ –Ω–µ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é —á–∞—Å—Ç—å.
# 

# In[1]:


import os
import re
from pathlib import Path

import numpy as np
import pandas as pd

from PIL import Image

from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score

from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression

# –î–ª—è CNN (–Ω–µ–π—Ä–æ—Å–µ—Ç–∏)
import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler
from torchvision import transforms


# ## üîπ  –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö

# ### –ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ –ø–∞–ø–∫–∞–º (–æ—Å–Ω–æ–≤–Ω–æ–π —Å–ø–æ—Å–æ–±)
# –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–ª–∞—Å—Å –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –ø–∞–ø–∫–∏ –∏ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç —Ä—É—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏–º—ë–Ω —Ñ–∞–π–ª–æ–≤

# In[3]:


#(–∫–ª–∞—Å—Å = –∏–º—è –ø–∞–ø–∫–∏)

DATASET_DIR = Path("dataset")

IMG_EXTS = {".jpg", ".jpeg", ".png", ".bmp", ".webp"}

rows = []
for class_dir in sorted([p for p in DATASET_DIR.iterdir() if p.is_dir()]):
    label = class_dir.name
    for img_path in class_dir.rglob("*"):
        if img_path.suffix.lower() in IMG_EXTS:
            rows.append({"path": str(img_path), "label": label})

df = pd.DataFrame(rows)
print("–í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:", len(df))
print("–ö–ª–∞—Å—Å—ã:", df["label"].unique())
print(df["label"].value_counts())


# ### –ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ –∏–º–µ–Ω–∞–º —Ñ–∞–π–ª–æ–≤
# –î–ª—è –º–µ–Ω–µ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞, –≥–¥–µ –º–µ—Ç–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞, —Ä–µ–∞–ª–∏–∑—É–µ–º –æ—Ç–¥–µ–ª—å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é:

# In[5]:


DATASET_DIR_FLAT = Path("dataset")  

def label_from_filename(filename: str) -> str:
    stem = Path(filename).stem
    return re.split(r"[_-]", stem)[0]

rows2 = []
for img_path in DATASET_DIR_FLAT.rglob("*"):
    if img_path.is_file() and img_path.suffix.lower() in IMG_EXTS:
        rows2.append({"path": str(img_path), "label": label_from_filename(img_path.name)})

df2 = pd.DataFrame(rows2)
print("–í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:", len(df2))
print("–ö–ª–∞—Å—Å—ã:", df2["label"].unique())
print(df2["label"].value_counts())


# ## üîπ  –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
# 
# –ü–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ **–ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –∫ –ø–æ–¥–∞—á–µ –≤ –º–æ–¥–µ–ª—å**. –í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å:
# 
# - –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω—ã –≤ –µ–¥–∏–Ω—ã–π —Ü–≤–µ—Ç–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç (–æ–±—ã—á–Ω–æ RGB),
# - –ü—Ä–∏–≤–µ–¥–µ–Ω—ã –∫ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–º—É —Ä–∞–∑–º–µ—Ä—É (–Ω–∞–ø—Ä–∏–º–µ—Ä, 224√ó224 –ø–∏–∫—Å–µ–ª–µ–π),
# - –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã (–∑–Ω–∞—á–µ–Ω–∏—è –ø–∏–∫—Å–µ–ª–µ–π –ø—Ä–∏–≤–µ–¥–µ–Ω—ã –∫ –¥–∏–∞–ø–∞–∑–æ–Ω—É [0, 1] –∏–ª–∏ [-1, 1]).
# 
# –≠—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ, –ø–æ—Ç–æ–º—É —á—Ç–æ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ **–Ω–µ –º–æ–≥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ —Ä–∞–∑–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞**, –∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è **—É—Å–∫–æ—Ä—è–µ—Ç –∏ —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä—É–µ—Ç –æ–±—É—á–µ–Ω–∏–µ**.
# 

# In[6]:


# —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ numpy (RGB + resize + –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è)

TARGET_SIZE = (128, 128)

def preprocess_pil_to_numpy(img_path: str, target_size=TARGET_SIZE) -> np.ndarray:
    img = Image.open(img_path).convert("RGB")
    img = img.resize(target_size)
    arr = np.array(img, dtype=np.float32) / 255.0  # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤ [0, 1]
    return arr  # shape: (H, W, 3)

# —Ç–µ—Å—Ç
sample_path = df["path"].iloc[0]
x = preprocess_pil_to_numpy(sample_path)


# In[7]:


#transforms –¥–ª—è PyTorch

torch_transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.Lambda(lambda img: img.convert("RGB")),
    transforms.ToTensor(), 
    # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é mean/std, –Ω–æ –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ToTensor()
])


# ## üîπ  –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤ (—á—Ç–æ–±—ã ‚Äú–ø—Ä–∏–º–µ—Ä–æ–≤ –±—ã–ª–æ +- –ø–æ—Ä–æ–≤–Ω—É‚Äù)
# 
# –í —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è **–¥–∏—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã**: –æ–¥–Ω–∏ –ø–æ—Ä–æ–¥—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã —Å–æ—Ç–Ω—è–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –¥—Ä—É–≥–∏–µ ‚Äî –≤—Å–µ–≥–æ –¥–µ—Å—è—Ç–∫–æ–º. –≠—Ç–æ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ —Ç–æ–º—É, —á—Ç–æ –º–æ–¥–µ–ª—å **¬´—É—á–∏—Ç—Å—è –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å¬ª —Ä–µ–¥–∫–∏–µ –∫–ª–∞—Å—Å—ã**.

# ###  –î–ª—è RandomForest (sklearn):
# 
# –î–æ–±–∞–≤—å—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä `class_weight="balanced"` –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –º–æ–¥–µ–ª–∏ ‚Äî —ç—Ç–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤–∑–≤–µ—Å–∏—Ç –æ—à–∏–±–∫–∏ –Ω–∞ —Ä–µ–¥–∫–∏—Ö –∫–ª–∞—Å—Å–∞—Ö —Å–∏–ª—å–Ω–µ–µ.

# In[8]:


from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(n_estimators=100, class_weight="balanced", random_state=42)


# ### –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ ‚Äú—á—Ç–æ–±—ã –ø–æ—Ä–æ–≤–Ω—É‚Äù = WeightedRandomSampler
# –ß—Ç–æ–±—ã –∫–ª–∞—Å—Å—ã –≤—Å—Ç—Ä–µ—á–∞–ª–∏—Å—å –ø—Ä–∏–º–µ—Ä–Ω–æ –æ–¥–∏–Ω–∞–∫–æ–≤–æ –≤ –æ–±—É—á–µ–Ω–∏–∏ ‚Äî –¥–µ–ª–∞–π —Å–µ–º–ø–ª–∏–Ω–≥ —á–µ—Ä–µ–∑ WeightedRandomSampler.

# In[9]:


import torch
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, WeightedRandomSampler

# 1. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(degrees=15),
    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.1),
    transforms.RandomGrayscale(p=0.1),
    transforms.RandomErasing(p=0.3, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=0),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

dataset = datasets.ImageFolder(root="dataset", transform=train_transform)

# 3. –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ —á–µ—Ä–µ–∑ —Å–µ–º–ø–ª–µ—Ä
targets = torch.tensor(dataset.targets) 
class_count = torch.bincount(targets)
class_weight = 1.0 / class_count.float()
sample_weight = class_weight[targets]

sampler = WeightedRandomSampler(
    weights=sample_weight,
    num_samples=len(dataset),
    replacement=True
)

# 4. –°–æ–∑–¥–∞—ë–º DataLoader
train_loader = DataLoader(dataset, batch_size=32, sampler=sampler, num_workers=2)

print(f" –î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω: {len(dataset)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, {len(dataset.classes)} –∫–ª–∞—Å—Å–æ–≤")
print(f" DataLoader —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π –≥–æ—Ç–æ–≤!")


# ### –î–ª—è YOLOv8-cls (Ultralytics)
# –í YOLOv8 –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –æ–±—ã—á–Ω–æ ‚Äú–µ—Å—Ç‚Äù —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫, –∞ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫—É —á–∞—â–µ —Ä–µ—à–∞—é—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–∫–æ–π –¥–∞–Ω–Ω—ã—Ö (–æ–≤–µ—Ä—Å—ç–º–ø–ª–∏–Ω–≥ —Ä–µ–¥–∫–∏—Ö –∫–ª–∞—Å—Å–æ–≤ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ–º/–¥–æ–ø-–∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è–º–∏) –∏–ª–∏ —Å–≤–æ–∏–º–∏ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞–º–∏, –ø–æ—Ç–æ–º—É —á—Ç–æ ‚Äú—Å–∫–µ–π–ª–µ—Ä‚Äù –∫–∞–∫ –≤ sklearn —Ç–∞–º –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è ‚Äî –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è/–ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ —Å–ø—Ä—è—Ç–∞–Ω—ã –≤–Ω—É—Ç—Ä–∏ –ø–∞–π–ø–ª–∞–π–Ω–∞.
# 

# ## üîπ –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π 
# 
# –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è ‚Äî —ç—Ç–æ **–∫–ª—é—á–µ–≤–æ–π –ø—Ä–∏—ë–º** –≤ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–º –∑—Ä–µ–Ω–∏–∏, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å –æ–±—ä—ë–º –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –ø–æ–≤—ã—Å–∏—Ç—å —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –∫ –≤–∞—Ä–∏–∞—Ü–∏—è–º –≤–æ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
# 
# –¶–µ–ª—å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ ‚Äî **—Å–º–æ–¥–µ–ª–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è —Å—ä—ë–º–∫–∏**, —Ç–∞–∫–∏–µ –∫–∞–∫:
# - –î—Ä—É–≥–æ–π —Ä–∞–∫—É—Ä—Å (–ø–æ–≤–æ—Ä–æ—Ç, –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ),
# - –ò–∑–º–µ–Ω—ë–Ω–Ω–æ–µ –æ—Å–≤–µ—â–µ–Ω–∏–µ (—è—Ä–∫–æ—Å—Ç—å, –∫–æ–Ω—Ç—Ä–∞—Å—Ç),
# - –ß–∞—Å—Ç–∏—á–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ –æ–±—ä–µ–∫—Ç–∞ (—Å–ª—É—á–∞–π–Ω–æ–µ —Å—Ç–∏—Ä–∞–Ω–∏–µ),
# - –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Ü–≤–µ—Ç–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ (—á—ë—Ä–Ω–æ-–±–µ–ª—ã–π —Ä–µ–∂–∏–º).
# 
# –≠—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç –º–æ–¥–µ–ª–∏ **–Ω–µ –ø–µ—Ä–µ–æ–±—É—á–∞—Ç—å—Å—è** –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã, –∞ **–Ω–∞—É—á–∏—Ç—å—Å—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å —Å—É—Ç—å –æ–±—ä–µ–∫—Ç–∞**.
# 
# ### –û—Å–Ω–æ–≤–Ω—ã–µ –≤–∏–¥—ã –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
# 
# | –¢–∏–ø –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ | –û–ø–∏—Å–∞–Ω–∏–µ | –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è |
# |------------------|--------|----------------------|
# | **–ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ** | –ó–µ—Ä–∫–∞–ª—å–Ω–æ–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–π –æ—Å–∏. | –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ (–ª–∏—Ü–∞, —Å–æ–±–∞–∫–∏, –∞–≤—Ç–æ–º–æ–±–∏–ª–∏). |
# | **–ü–æ–≤–æ—Ä–æ—Ç** | –ü–æ–≤–æ—Ä–æ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ —Å–ª—É—á–∞–π–Ω—ã–π —É–≥–æ–ª –≤ –∑–∞–¥–∞–Ω–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ. | –ò–º–∏—Ç–∏—Ä—É–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–µ —É–≥–ª–∞ —Å—ä—ë–º–∫–∏. |
# | **–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–≤–µ—Ç–∞** | –°–ª—É—á–∞–π–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —è—Ä–∫–æ—Å—Ç–∏, –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞, –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç–∏ –∏ –æ—Ç—Ç–µ–Ω–∫–∞. | –ú–æ–¥–µ–ª–∏—Ä—É–µ—Ç —Ä–∞–∑–Ω—ã–µ —É—Å–ª–æ–≤–∏—è –æ—Å–≤–µ—â–µ–Ω–∏—è. |
# | **–ß—ë—Ä–Ω–æ-–±–µ–ª—ã–π —Ä–µ–∂–∏–º** | –°–ª—É—á–∞–π–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –≥—Ä–∞–¥–∞—Ü–∏–∏ —Å–µ—Ä–æ–≥–æ. | –ü–æ–≤—ã—à–∞–µ—Ç —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ —Ü–≤–µ—Ç–æ–≤—ã–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞–º. |
# | **–°–ª—É—á–∞–π–Ω–æ–µ —Å—Ç–∏—Ä–∞–Ω–∏–µ (Random Erasing)** | –ó–∞–∫—Ä–∞—à–∏–≤–∞–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–æ–≥–æ —É—á–∞—Å—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á—ë—Ä–Ω—ã–º —Ü–≤–µ—Ç–æ–º. | –ò–º–∏—Ç–∏—Ä—É–µ—Ç –ø–æ—Ç–µ—Ä—é —á–∞—Å—Ç–∏ –æ–±—ä–µ–∫—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∑–∞ –∫—É—Å—Ç–æ–º). |
# 
# ### –ü–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
# 
# –î–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫—É `torchvision.transforms`, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —É–¥–æ–±–Ω—ã–µ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã.
# 
# # –ü–æ–ª—É—á–∞–µ–º –≤ –∏—Ç–æ–≥–µ –±–æ–ª—å—à–æ–π —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å—ç—Ç dataset_aug

# In[16]:


from pathlib import Path
import shutil
import random
import numpy as np
import pandas as pd
from PIL import Image
from torchvision import transforms
from sklearn.model_selection import train_test_split

TARGET_SIZE = (128, 128)

DATASET_DIR = Path("dataset")
TRAIN_AUG_DIR = Path("dataset_train_aug")   # train = –æ—Ä–∏–≥–∏–Ω–∞–ª—ã train + –∏—Ö –∞—É–≥–º–µ–Ω—Ç—ã
TEST_CLEAN_DIR = Path("dataset_test_clean") # test = —Ç–æ–ª—å–∫–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—ã test
IMG_EXTS = {".jpg", ".jpeg", ".png", ".bmp", ".webp"}

# 1) –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–≤
rows = []
for class_dir in sorted([p for p in DATASET_DIR.iterdir() if p.is_dir()]):
    label = class_dir.name
    for img_path in class_dir.rglob("*"):
        if img_path.suffix.lower() in IMG_EXTS:
            rows.append({"path": str(img_path), "label": label})
df = pd.DataFrame(rows)

# 2) Split –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–≤
train_df, test_df = train_test_split(
    df, test_size=0.2, random_state=42, stratify=df["label"]
)

def reset_dir(p: Path):
    if p.exists():
        shutil.rmtree(p)
    p.mkdir(parents=True, exist_ok=True)

def copy_split(df_part: pd.DataFrame, out_root: Path):
    for _, row in df_part.iterrows():
        src = Path(row["path"])
        label = row["label"]
        (out_root / label).mkdir(parents=True, exist_ok=True)
        shutil.copy2(src, out_root / label / src.name)

reset_dir(TRAIN_AUG_DIR)
reset_dir(TEST_CLEAN_DIR)

# 3) –ö–ª–∞–¥—ë–º –æ—Ä–∏–≥–∏–Ω–∞–ª—ã: train -> TRAIN_AUG_DIR, test -> TEST_CLEAN_DIR
copy_split(train_df, TRAIN_AUG_DIR)
copy_split(test_df, TEST_CLEAN_DIR)

# 4) –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ (–¢–û–õ–¨–ö–û –î–õ–Ø TRAIN)
augment = transforms.Compose([
    transforms.Resize(TARGET_SIZE),
    transforms.RandomRotation(degrees=20),
    transforms.ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25),
    transforms.RandomGrayscale(p=0.25),  # 25% –±—É–¥—É—Ç —á/–±
])

def add_black_square(pil_img: Image.Image, max_frac=0.35) -> Image.Image:
    img = pil_img.copy()
    w, h = img.size
    rw = int(w * random.uniform(0.1, max_frac))
    rh = int(h * random.uniform(0.1, max_frac))
    x0 = random.randint(0, max(0, w - rw))
    y0 = random.randint(0, max(0, h - rh))
    arr = np.array(img)
    arr[y0:y0+rh, x0:x0+rw, :] = 0
    return Image.fromarray(arr)

def augment_train_only(train_df: pd.DataFrame, copies_per_image=2):
    for _, row in train_df.iterrows():
        src_path = Path(row["path"])
        label = row["label"]
        out_class_dir = TRAIN_AUG_DIR / label

        for k in range(copies_per_image):
            img = Image.open(src_path).convert("RGB")
            img = augment(img)
            img = add_black_square(img)
            img.save(out_class_dir / f"{src_path.stem}_aug{k}{src_path.suffix}")

augment_train_only(train_df, copies_per_image=2)

print("Train (with aug):", TRAIN_AUG_DIR)
print("Test (clean):", TEST_CLEAN_DIR)
print("Train orig:", len(train_df), "Test:", len(test_df))


# In[11]:


# –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç

rows_aug = []
for class_dir in sorted([p for p in TRAIN_AUG_DIR.iterdir() if p.is_dir()]):
    label = class_dir.name
    for img_path in class_dir.rglob("*"):
        if img_path.suffix.lower() in IMG_EXTS:
            rows_aug.append({"path": str(img_path), "label": label})

df_aug = pd.DataFrame(rows_aug)
print("–í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ—Å–ª–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏:", len(df_aug))
print(df_aug["label"].value_counts())


# ## üîπ Train/test split + –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤
# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ (stratify)
# –ó–∞—á–µ–º: —á—Ç–æ–±—ã –¥–æ–ª–∏ –∫–ª–∞—Å—Å–æ–≤ –≤ train/test –±—ã–ª–∏ –ø–æ—Ö–æ–∂–∏.
# 
# –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
# –ï—Å—Ç—å 2 –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–∞:
# 
# WeightedRandomSampler (–¥–ª—è DataLoader –≤ PyTorch) ‚Äî –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ —á–∞—â–µ –ø–æ–¥–±–∏—Ä–∞—Ç—å —Ä–µ–¥–∫–∏–µ –∫–ª–∞—Å—Å—ã.
# 
# class_weight (–¥–ª—è sklearn –º–æ–¥–µ–ª–µ–π) ‚Äî —à—Ç—Ä–∞—Ñ–æ–≤–∞—Ç—å –æ—à–∏–±–∫–∏ –ø–æ —Ä–µ–¥–∫–∏–º –∫–ª–∞—Å—Å–∞–º —Å–∏–ª—å–Ω–µ–µ.

# In[12]:


train_df, test_df = train_test_split(
    df_aug,
    test_size=0.2,
    random_state=42,
    stratify=df_aug["label"]
)

print("Train:", len(train_df), "Test:", len(test_df))
print("Train class counts:\n", train_df["label"].value_counts())
print("Test class counts:\n", test_df["label"].value_counts())


# ## üîπ  –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∑–∞–¥–∞—á –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è
# 
# | –ó–∞–¥–∞—á–∞ | –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –º–æ–¥–µ–ª–∏ | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å |
# |--------|------------------|-------------------|
# | **–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è** | ResNet, EfficientNet, Vision Transformer (ViT), **YOLOv8-cls** | –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –Ω–∞ –≤—Å—ë–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ |
# | **–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤** | YOLOv8, Faster R-CNN, SSD | –ù—É–∂–Ω—ã –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∏ –∫–ª–∞—Å—Å –∫–∞–∂–¥–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ |
# | **–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è** | U-Net, Mask R-CNN, YOLOv8-seg | –¢—Ä–µ–±—É–µ—Ç—Å—è —Ç–æ—á–Ω–æ–µ –≤—ã–¥–µ–ª–µ–Ω–∏–µ –≥—Ä–∞–Ω–∏—Ü –æ–±—ä–µ–∫—Ç–∞ |
# | **–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π** | Stable Diffusion, GAN | –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π |
# | **–ü–æ–≤—ã—à–µ–Ω–∏–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è** | ESRGAN, SRCNN | –£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π |
# 
# > –î–ª—è –∑–∞–¥–∞—á –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–∞ —á–µ–º–ø–∏–æ–Ω–∞—Ç–µ **—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –Ω–∞—á–∏–Ω–∞—Ç—å —Å YOLOv8-cls –∏–ª–∏ EfficientNet-B0**.
# 

# ### üîπ –ú–æ–¥–µ–ª—å 1: RandomForest –ø–æ ¬´—á–∏—Å–ª–∞–º¬ª (–ø–∏–∫—Å–µ–ª–∏ -> –≤–µ–∫—Ç–æ—Ä)
# –ò–¥–µ—è: –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É 
# 128√ó128√ó3 –≤ –≤–µ–∫—Ç–æ—Ä –¥–ª–∏–Ω—ã 128‚àó128‚àó3 –∏ –æ–±—É—á–∏—Ç—å RandomForest. 

# In[27]:


# –Ø—á–µ–π–∫–∞ 5A: –∫–æ–¥–∏—Ä—É–µ–º –∫–ª–∞—Å—Å—ã —á–∏—Å–ª–∞–º–∏
classes = sorted(train_df["label"].unique())
class_to_id = {c: i for i, c in enumerate(classes)}
id_to_class = {i: c for c, i in class_to_id.items()}

train_df = train_df.copy()
test_df = test_df.copy()
train_df["y"] = train_df["label"].map(class_to_id)
test_df["y"] = test_df["label"].map(class_to_id)

print(class_to_id)


# In[28]:


# –¥–µ–ª–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è sklearn 

def build_X_y(df_in: pd.DataFrame, target_size=TARGET_SIZE):
    X_list, y_list = [], []
    for _, row in df_in.iterrows():
        arr = preprocess_pil_to_numpy(row["path"], target_size=target_size)  # (H,W,3) float32 [0..1]
        feat = arr.reshape(-1) 
        X_list.append(feat)
        y_list.append(int(row["y"]))
    return np.stack(X_list), np.array(y_list)

X_train, y_train = build_X_y(train_df)
X_test, y_test = build_X_y(test_df)

print(X_train.shape, y_train.shape)


# In[29]:


# RandomForest –æ–±—É—á–µ–Ω–∏–µ

rf = RandomForestClassifier(
    n_estimators=300,
    random_state=42,
    class_weight="balanced"  # –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –≤–Ω—É—Ç—Ä–∏ –º–æ–¥–µ–ª–∏
)
rf.fit(X_train, y_train)

pred_rf = rf.predict(X_test)
print("Accuracy:", accuracy_score(y_test, pred_rf))
print("F1 macro:", f1_score(y_test, pred_rf, average="macro"))
print(classification_report(y_test, pred_rf, target_names=classes))


# ## üîπ –ú–æ–¥–µ–ª—å 2: Logistic Regression (–µ—â—ë –æ–¥–∏–Ω baseline –ø–æ —á–∏—Å–ª–∞–º)

# In[30]:


#  LogisticRegression (—á–∞—Å—Ç–æ —Å–∏–ª—å–Ω–µ–µ, —á–µ–º –∫–∞–∂–µ—Ç—Å—è, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –∏—Ç–µ—Ä–∞—Ü–∏–π)

lr = LogisticRegression(
    max_iter=2000,
    class_weight="balanced",
    n_jobs=None
)
lr.fit(X_train, y_train)

pred_lr = lr.predict(X_test)
print("Accuracy:", accuracy_score(y_test, pred_lr))
print("F1 macro:", f1_score(y_test, pred_lr, average="macro"))
print(classification_report(y_test, pred_lr, target_names=classes))


# ## üîπ YOLO –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (YOLO-cls)
# 

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∏–∑ dataset_aug
# –°–µ–π—á–∞—Å: dataset_aug/Beagle/*.jpg, dataset_aug/Boxer/*.jpg –∏ —Ç.–ø.
# YOLO-cls –æ–∂–∏–¥–∞–µ—Ç —Ç–∞–∫:
# dataset_yolo_cls/train/<class>/*.jpg –∏ dataset_yolo_cls/val/<class>/*.jpg (–∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ test).
# ‚Äã

# In[15]:


import shutil
from pathlib import Path

SRC_TRAIN = Path("dataset_train_aug")
SRC_VAL = Path("dataset_test_clean")   # —á–∏—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
DST = Path("dataset_yolo_cls")

TRAIN_DIR = DST / "train"
VAL_DIR = DST / "val"

if DST.exists():
    shutil.rmtree(DST)
TRAIN_DIR.mkdir(parents=True, exist_ok=True)
VAL_DIR.mkdir(parents=True, exist_ok=True)

def copy_tree(src_root: Path, dst_root: Path):
    for class_dir in src_root.iterdir():
        if not class_dir.is_dir():
            continue
        out = dst_root / class_dir.name
        out.mkdir(parents=True, exist_ok=True)
        for p in class_dir.glob("*"):
            if p.is_file():
                shutil.copy2(p, out / p.name)

copy_tree(SRC_TRAIN, TRAIN_DIR)
copy_tree(SRC_VAL, VAL_DIR)

print("YOLO dataset ready:", DST)


# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ ultralytics
# YOLO –æ—Ç Ultralytics —Ç—Ä–µ–Ω–∏—Ä—É–µ—Ç—Å—è —á–µ—Ä–µ–∑ from ultralytics import YOLO –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–µ–∂–∏–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å yolo11n-cls.pt

# In[16]:


get_ipython().system('pip install -U ultralytics')


# In[17]:


from ultralytics import YOLO


# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö ‚Äî —ç—Ç–æ —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –º–æ–¥–µ–ª—å ‚Äú–ø—Ä–æ–π–¥—ë—Ç‚Äù –ø–æ –≤—Å–µ–º—É train‚Äë–Ω–∞–±–æ—Ä—É, –Ω–æ –≤ Ultralytics –æ–±—ã—á–Ω–æ —Å—Ç–∞–≤—è—Ç epochs —Å –∑–∞–ø–∞—Å–æ–º –∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç `patience` (early stopping), —á—Ç–æ–±—ã –æ–±—É—á–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–∏–ª–æ—Å—å, –∫–æ–≥–¥–∞ –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ val –ø–µ—Ä–µ—Å—Ç–∞–ª–∏ —É–ª—É—á—à–∞—Ç—å—Å—è.
# 
# ## –°–∫–æ–ª—å–∫–æ —ç–ø–æ—Ö —Å—Ç–∞–≤–∏—Ç—å  (–ø—Ä–∞–∫—Ç–∏—á–Ω–æ)
# - –î–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —á–µ—Ä–Ω–æ–≤–æ–≥–æ –ø—Ä–æ–≥–æ–Ω–∞: **10‚Äì30 —ç–ø–æ—Ö** (—á—Ç–æ–±—ã –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç –∏ –º–µ—Ç—Ä–∏–∫–∏ —Ä–∞—Å—Ç—É—Ç).
# - –î–ª—è ‚Äú–Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ‚Äù –æ–±—É—á–µ–Ω–∏—è: —á–∞—Å—Ç–æ —Å—Ç–∞–≤—è—Ç **100‚Äì300 —ç–ø–æ—Ö**, –∞ –æ—Å—Ç–∞–Ω–æ–≤–∫—É –¥–æ–≤–µ—Ä—è—é—Ç `patience`, —á—Ç–æ–±—ã –Ω–µ —Ç—Ä–∞—Ç–∏—Ç—å –ª–∏—à–Ω–µ–µ –≤—Ä–µ–º—è –∏ –Ω–µ —É–π—Ç–∏ –≤ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ.
# - –ï—Å–ª–∏ –¥–∞—Ç–∞—Å–µ—Ç –º–∞–ª–µ–Ω—å–∫–∏–π/–ø—Ä–æ—Å—Ç–æ–π, –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –≤—ã–π—Ç–∏ –Ω–∞ –ø–ª–∞—Ç–æ –±—ã—Å—Ç—Ä–æ ‚Äî —Ç–æ–≥–¥–∞ `patience` (–Ω–∞–ø—Ä–∏–º–µ—Ä 10‚Äì20) —Å—Ä–∞–±–æ—Ç–∞–µ—Ç —Ä–∞–Ω—å—à–µ, –∏ —Ä–µ–∞–ª—å–Ω—ã–µ —ç–ø–æ—Ö–∏ –±—É–¥—É—Ç –º–µ–Ω—å—à–µ –∑–∞–¥–∞–Ω–Ω—ã—Ö.
# 
# ## –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä—è–º–æ –≤ –∫–æ–¥–µ
# 1) ‚Äú–ë—ã—Å—Ç—Ä–æ –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ‚Äù:
# ```python
# results = model.train(
#     data="dataset_yolo_cls",
#     epochs=50,
#     patience=10,   # –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è, –µ—Å–ª–∏ –Ω–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è 10 —ç–ø–æ—Ö 
#     imgsz=224,
#     batch=32
# )
# ```
# 
# 2) ‚Äú–° –∑–∞–ø–∞—Å–æ–º, –ø—É—Å—Ç—å —Å–∞–º–∞ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è‚Äù:
# ```python
# results = model.train(
#     data="dataset_yolo_cls",
#     epochs=300,    # —á–∞—Å—Ç—ã–π —Å—Ç–∞—Ä—Ç–æ–≤—ã–π –æ—Ä–∏–µ–Ω—Ç–∏—Ä 
#     patience=20,
#     imgsz=224,
#     batch=32
# )
# ```
# 

# In[22]:


from ultralytics import YOLO
from pathlib import Path

DST = Path("dataset_yolo_cls")

model = YOLO("yolo11n-cls.pt")  # –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ 

results = model.train(
    data=str(DST),     # –∫–æ—Ä–µ–Ω—å, –≥–¥–µ –ª–µ–∂–∞—Ç train/val
    epochs=10,
    imgsz=224,
    batch=32,
    patience=10        # —Ä–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞, –µ—Å–ª–∏ –º–µ—Ç—Ä–∏–∫–∞ –Ω–µ —É–ª—É—á—à–∞–µ—Ç—Å—è
)
model.save('dogs_yolo_model.pt')


# In[23]:


val_res = model.val(data=str(DST))
val_res


# –ß—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç –∫–∞–∂–¥–∞—è –º–µ—Ç—Ä–∏–∫–∞:
# Accuracy: –¥–æ–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π (top‚Äë1 –ø–æ–ø–∞–¥–∞–Ω–∏–µ).
# 
# Top‚Äë5 accuracy: –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∫–ª–∞—Å—Å –≤ —Ç–æ–ø‚Äë5 –ø–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ (–≤–∞–∂–Ω–æ –ø—Ä–∏ –±–æ–ª—å—à–æ–º —á–∏—Å–ª–µ –∫–ª–∞—Å—Å–æ–≤).
# ‚Äã
# 
# Precision (macro): ‚Äú–∫–æ–≥–¥–∞ –º–æ–¥–µ–ª—å —Å–∫–∞–∑–∞–ª–∞ –∫–ª–∞—Å—Å, –Ω–∞—Å–∫–æ–ª—å–∫–æ —á–∞—Å—Ç–æ –ø—Ä–∞–≤–∞‚Äù, —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Å–∞–º –±–µ–∑ —É—á—ë—Ç–∞ —Ä–∞–∑–º–µ—Ä–∞ –∫–ª–∞—Å—Å–æ–≤.
# 
# Recall (macro): ‚Äú—Å–∫–æ–ª—å–∫–æ –æ–±—ä–µ–∫—Ç–æ–≤ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ –º–æ–¥–µ–ª—å –Ω–∞—à–ª–∞‚Äù, —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Å–∞–º.
# 
# F1 (macro): –±–∞–ª–∞–Ω—Å precision –∏ recall, —á–µ—Å—Ç–Ω–µ–µ –ø—Ä–∏ –¥–∏—Å–±–∞–ª–∞–Ω—Å–µ.
# 
# Balanced accuracy: —Å—Ä–µ–¥–Ω–∏–π recall –ø–æ –∫–ª–∞—Å—Å–∞–º (–ø–æ–ª–µ–∑–Ω–æ –ø—Ä–∏ –¥–∏—Å–±–∞–ª–∞–Ω—Å–µ).
# 
# Confusion matrix: –∫–∞–∫–∏–µ –∫–ª–∞—Å—Å—ã —Å –∫–∞–∫–∏–º–∏ –ø—É—Ç–∞—é—Ç—Å—è.
# 
# ROC-AUC (ovr): –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ –º–æ–¥–µ–ª—å —Ä–∞–Ω–∂–∏—Ä—É–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∫–ª–∞—Å—Å –≤—ã—à–µ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º (–Ω—É–∂–Ω—ã –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ –º–µ—Ç–∫–∏).

# In[24]:


import numpy as np
from pathlib import Path

VAL_DIR = Path("dataset_yolo_cls/val")
IMG_EXTS = {".jpg", ".jpeg", ".png", ".bmp", ".webp"}

# —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –∏ –∏—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ (–∏–∑ –ø–∞–ø–∫–∏)
val_paths = []
y_true_names = []

for class_dir in sorted([p for p in VAL_DIR.iterdir() if p.is_dir()]):
    for p in class_dir.rglob("*"):
        if p.is_file() and p.suffix.lower() in IMG_EXTS:
            val_paths.append(str(p))
            y_true_names.append(class_dir.name)

# –¥–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –±–∞—Ç—á–∞–º–∏ (Ultralytics —Å–∞–º –±–∞—Ç—á–∏—Ç)
pred_results = model.predict(source=val_paths, imgsz=224, verbose=False)

# –ø—Ä–µ–≤—Ä–∞—â–∞–µ–º –≤ id-–º–µ—Ç–∫–∏
name_to_id = {v: int(k) for k, v in model.names.items()}  # model.names: id->name 
n_classes = len(model.names)

y_true = np.array([name_to_id[n] for n in y_true_names], dtype=int)

y_pred = []
y_proba = []

for r in pred_results:
    # probs —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–æ–≤ + top1/top5 –∏ confidence 
    probs = r.probs
    y_pred.append(int(probs.top1))                 # id top-1 –∫–ª–∞—Å—Å–∞ 
    y_proba.append(probs.data.cpu().numpy())       # –ø–æ–ª–Ω—ã–π –≤–µ–∫—Ç–æ—Ä –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π 

y_pred = np.array(y_pred, dtype=int)
y_proba = np.stack(y_proba)

print("val samples:", len(y_true), "classes:", n_classes)


# In[26]:


from sklearn.metrics import (
    accuracy_score, balanced_accuracy_score,
    precision_score, recall_score, f1_score,
    confusion_matrix, classification_report,
    top_k_accuracy_score, roc_auc_score
)

print("Accuracy (top-1):", accuracy_score(y_true, y_pred))
print("Balanced accuracy:", balanced_accuracy_score(y_true, y_pred))
print("Precision macro:", precision_score(y_true, y_pred, average="macro", zero_division=0))
print("Recall macro:", recall_score(y_true, y_pred, average="macro", zero_division=0))
print("F1 macro:", f1_score(y_true, y_pred, average="macro", zero_division=0))
print("F1 weighted:", f1_score(y_true, y_pred, average="weighted", zero_division=0))

print("Top-5 accuracy:", top_k_accuracy_score(y_true, y_proba, k=min(5, y_proba.shape[1])))

# ROC-AUC –¥–ª—è –º—É–ª—å—Ç–∏–∫–ª–∞—Å—Å–∞ 
try:
    print("ROC-AUC ovr macro:", roc_auc_score(y_true, y_proba, multi_class="ovr", average="macro"))
    print("ROC-AUC ovr weighted:", roc_auc_score(y_true, y_proba, multi_class="ovr", average="weighted"))
except Exception as e:
    print("ROC-AUC error:", e)

print("\nConfusion matrix:\n", confusion_matrix(y_true, y_pred))
print("\nClassification report:\n", classification_report(y_true, y_pred, target_names=[model.names[i] for i in range(n_classes)]))

